{"meta":{"title":"JingjieLi’s Brain","subtitle":"A senior from Xi’an Jiaotong University(XJTU)","description":"My Personal Blog","author":"Jingjie Li","url":"http://www.jingjie.site"},"pages":[{"title":"Timeline","date":"2017-09-22T16:42:40.000Z","updated":"2017-09-22T16:42:40.000Z","comments":true,"path":"timeline/index.html","permalink":"http://www.jingjie.site/timeline/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"Tags & Catagories","date":"2017-09-22T16:41:45.000Z","updated":"2017-09-22T16:41:45.000Z","comments":true,"path":"tags/index.html","permalink":"http://www.jingjie.site/tags/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"Something About Jingjie","date":"2017-11-03T17:19:55.000Z","updated":"2018-12-17T14:22:56.000Z","comments":true,"path":"about/index.html","permalink":"http://www.jingjie.site/about/index.html","excerpt":"","text":"Hi, I’m Jingjie Li, a senior student from Xi’an Jiaotong University(XJTU), Majoring in BME(BioMedical Engineering). My research interest is neural mechanism of sensory working memory: how our sensory working memory is represented in our brain, and the ways this representation interacts with other neural activity in our sensory system. I would like to explore that problems using rodent: designing rodent behavioral hardwares and protocol, running rodent behavior trainning, doing electrophysiology, opto-genetics and math modeling. I’m currently applying for several Ph.D. Programs in Neuroscience! Also seeking for some chance and information about that. Neuroscience Education InfoIn July, 2016. I attended the 4th CLS/McG neuroscience summer school in Peking University. From Jun. 2017 to Sep. 2017. I attended the 1th Summer Undergraduate Research Program(SURP) at New York University Shanghai in Dr Jeffrey Erlich’s Lab. I attended NYU Shanghai SURP again in 2018 summer in Dr. Erlich’s lab again. You can download my CV here. Lab Research Experience2017 07 - 2017 09Undergraduate Researcher, NYU-ECNU Institute of Brain and Cognitive Science, New York University Shanghai Advisor: Dr. Jeffrey C. Erlich Project 1 : Visual working memory based decision making task for the Rodent(Jun. 2017 - Dec. 2017) I start to working with rodent in this project! In order to study how Visual Working Memory(VWM) is represented in rodent’s brain. The very first thing we need to do is to train them to do a VWM task, that’s what I did at that period: I designed a 9-stages experiment protocol to train mice to perform a visual working-memory guided orienting task based on the B-Pod rodent behavioral system in the lab.A report about my work can be found at NYU’s website. For more detail: Click HERE Project 2 : Spatio-temporal receptive fields in the rodent frontal orienting field (2018-06 - 2018-09) I learnt a lot hand-in experience about electrophysiology in this project! In this project, we firstly trained the rat to do a one-step orienting task. Rats are instructed by LEDs and they need to follow the LED light cue to do a 2-dimensional oriatational movement, from the center of a poke-wall to a cued direction. We simultaneously recorded its spike activity in FOF(Frontal Orienting Field) using open-ephys electrophysiology system. I mainly performed spike based analysis including PSTH plotting, curving curve and directional selectivity plotting. I mainly found that like human and macaque FEF, rat’s FOF neurons tunes for specific trajectories. Resembling like the finding in macaque’s FEF, rat’s FOF has fast low-latency response, about 90ms. In order to determine the representation of more complex trajectories in rat’s FOF, we carried out a multi-steps orienting task: rats were required to move their nose twice following two separately LED cues together with electrophysiology recording. In this experiment, I found that rat’s FOF can also tune for planning and prediction before the start of the second cue. Also, some FOF neurons tunes for the final goal rather than the intermitted first goal. In this project, I learnt spike sorting by observing and solving problems with a RA and a graduate student in our lab. I mainly contributed to spike based analysis such like PSTH plotting and tuning curve plotting. I wrote some functions based on Professor Erlich’s preliminary program for his 2011 neuron paper. Dr. Erlich presented part of our summer results on 2018 society for neuroscience meeting. Project 3 : Rodent Behavior Hardware Development - Power System and Sound Server System 2018-01 - 2018-07 (Part time from 2018-02 to 2018-06)&gt; In order to provide low latency and high performance sound to replace old MATLAB psychtoolbox based Bpod sound service program, I developed some hardware to improve rodent lab infrastructure. The new sound system was based on Rpi. I wrote some MATLAB and Python program based on ZMQ Socket which could enable the Bpod system to upload, sync and modify sound files. After the training protocol starts, the sound will be triggered by serial signal coming from Bpod Shield Arduino, which enable a ms-level latency sound trigger. In the Python program, I delicately designed call-back functions and multi-thread program which could control the stop and start of multiple sounds independently and precisely. In order to achieve high performance sound delivery, I also designed PCB to carry a high performance HiFi DAC IC and a Amplifier Chip. The testing results suggested that our new sound system can provide sound with low to 1.46ms latency in 44100 Hz with high performance. The code of this work was shared in our Erlich Lab Github: link Project 4 : History dependance modeling (time-normalization divisive model) of the experiential based delay-reward decision-making tasks for human subjects (Aug. 2017, Under postdoc Dr. Evgeniya Lukinova’s Project) In this project, I developed few computational models for measuring and detecting history dependence in a experiential based delay-reward decision-making tasks. I Found that bigger the delay the more history matters, however, the parameter responsible for the history is negligibly small. The model fails to beat the simple hyperbolic model in terms of BIC(Bayesian information criterion) on the same dataset. 2016 03 - NOWUndergraduate Researcher, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University Advisor: Prof. Badong Chen Project 1 : Visual image reconstruction using fMRI(In March, 2016) This work is about repeating a pioneering research, decode fMRI signal from primary visual cortex (V1) and reconstruct pattern image from fMRI signal (Miyawaki et al., 2008), meanwhile, I improved the accuracy of the reconstruction by about 4% (from about 80% to about 84%), using the improved MVPA method with SVM classifier (Norman et al., 2006). For more detail: Click HERE Project 2 : Modeling fMRI voxels dynamics with natural image stimulus(In May, 2016) This work is about repeating a pioneering research(Kay et al., 2008), modeling voxels activities in visual cortex using the Voxel-Wise Model (Naselaris et al., 2011), I successfully constructed a liner receptive field model for every voxels using the Gabor wavelet filter according to the encoding theory of the primary visual cortex (Hubel and Wiesel, 1968), without noise ceiling procedures I also got remarkable accuracy in the identification task (about 48.8%, meanwhile the chance level is about 0.8%). For more detail: Click HERE Project 3 : How visual working memory effects visual perception(Sep. 2016 - NOW) In this project, I’m using psychophysical experiments and functional imaging (fMRI) to study how previous visual working memory (VWM) content affect coming-up visual stimulus. I have presented part of my results on the Vision Sciences Society 2017 Annual Meeting. And we’ve get our paper ready to submit. Here is the abstract of our paper to be submitted:When viewing ambiguous or puzzle figures, perception will alternate spontaneously, but this alternation will cease if the visual stimulus is periodically removed from view. There may be some working memory trace or history dependence tract during the delay period, but it is poorly understood. Here, we used a serial unambiguous Structure-from-Motion (SFM)-delay-ambiguous SFM paradigm to explore the role of perceptual memory in visual working memory and the serial dependence effect. Additionally, we tried to use distractors to eliminate the internal representation of visual motion in the delay period. We found that 1) memorizing the rotational speed of SFM (i.e., visual working memory) in the delay period enhanced perceptual memory significantly, 2) distractors in the delay period impaired perceptual bias but did not affect working memory performance, and 3) the serial dependence effect size was negatively correlated with perceptual memory performance. Overall, our findings provide evidence to explain how visual working memory affects perceptual memory and, furthermore, the relationship between perceptual memory and the serial dependence effect. For more detail: Click HERE 2016 11 - 2017 05Undergraduate Researcher, Department of BioMedical Engineering, Xi’an Jiaotong UniversityAdvisor: Prof. Gang Wang Project 1 : Anesthesia monitoring using combination of Bispectral, WT, FFT and entropy analyze in EEG signal. In this project, my main work was to construct different signal processing algorithms, to identify difference between anesthesia and wake state in EEG signals. I tried to use 1) WT and FFT analyze to capture the time-frequency characteristics, 2) Bispectral to detect phase coupling characteristics, and 3) entropy\\ complexity analyze to capture the none-linearity characteristics of EEG signal. Then, I performed a ROC analysis to identify the performance of my algorithms. Results showed that my algorithms successfully detected significant difference between anesthesia and wake state. In this project, I gained a lot of useful skills about dealing with digital signals using MATLAB. Engineering Related Experience2018 03 - 2018 08First Prize (Highest), National Biomedical Engineering CompetitionAdvisor Prof.Jin Li and Prof.Xiang Chen Project: A ECG/Oximeter Monitor design using TI’s AFE4400 and ADS1293 IC, and MSP430MCU I made an attempt to make a portable ECG/Oximeter Monitor in this project. I mainly did the PCB design via Autodesk EAGLE, 3D printed accessories design, and some of the embedded system programming for TI’s MSP430 MCU. With the assistance of the smartphone APP and some embedded system programming from my collaborators, we submitted it to the National Biomedical Engineering Competition for College Students and won the first prize. The main skillset I obtained from this project is to build a complex circuit containing multiple ICs and make it work (including hardware debugging), which turned out to be very helpful when I worked on Bpod hardware in Dr. Erlich’s lab. We’ve open sourced all our design files, code, APP design and some debuging tools. The Github link is here. Skills Rodent Experiment: Handling rodents; Developing and running rodent experiment protocol using B-Pod System Programming: Python, MATLAB (Proficient); R (ggplot2); C; C++; Verilog HDL (FPGA); x86 Assembly; Git; SQL DB Hardware: PCB &amp; Circuit Design; MCU programming (MSP430, STM32, Arduino); Problem solving using IC. Electrophysiology (in vivo): Spike sorting; LFP analysis; PSTH analysis; Tuning analysis. Psychophysics: Psychtoolbox programming (MATLAB) &amp; basic experiment design skills fMRI Data Analysis: SPM12 preprocessing and univariate analysis; MVPA; Forward encoding model; Voxels activities modeling (Voxel-Wise Model) EEG Data Analysis: Running EEG experiments, ERP data analysis, Higher order nonlinear feature extracting. Publications2017 Jingjie Li, Hao Wu, Badong Chen. Visual working memory affects the perception of ambiguous SFM (structure-from-motion) by enhancing internal representation, Poster presented at the 17th Annual Meeting of the Vision Sciences Society. Naples, FL. Jingjie Li, Jinming Li, Badong Chen. “The Influence and Disassociation Effect Between Visual Working Memory and Serial Dependence effect to Perceptual Memory in a Bistable Perception Task”. (submitted to Vision Research) Courses (Only listed online courses)As cognitive neuroscience a interdisciplinary subject, we need some other skills and knowledge in order to carry out research in this field such like math and programming etc. In order to strengthen my programming skills and gain some knowledge about other interdisciplinary subjects(Data Science, Meachine Learning). I took several online courses(MOOCs), mainly in Coursea.org. For detiles CLICK HERE Introduction to Programming with MATLAB Meachine Learning Principles of fMRI 1 Neural Networks for Machine Learning Books I’ve read Kandel, E., &amp; Schwartz, J. (2013). Principles of Neural Science, Fifth Edition: McGraw-Hill Education. Dayan, P., &amp; Abbott, L. F. (2001). Theoretical neuroscience (Vol. 10): Cambridge, MA: MIT Press. Marr, D. (1982). Vision: A computational approach: Freeman. Honors2016 Siyuan Scholarship in Xi’an Jiaotong University Outstanding Student in Xi’an Jiaotong University 2017 Siyuan Scholarship in Xi’an Jiaotong University Outstanding Student in Xi’an Jiaotong University Contact MeMy Email: jingjie.li@nyu.edu jingjie.li@stu.xjtu.edu.cn lijingjiepoi@gmail.com My Wechat id: lijingjiepoi","raw":null,"content":null}],"posts":[{"title":"My own B-Pod System using FPGA and MATLAB","slug":"My-own-B-Pod-System-using-FPGA-and-MATLAB","date":"2017-12-08T13:59:09.000Z","updated":"2017-12-15T15:04:37.000Z","comments":true,"path":"2017/12/08/My-own-B-Pod-System-using-FPGA-and-MATLAB/","link":"","permalink":"http://www.jingjie.site/2017/12/08/My-own-B-Pod-System-using-FPGA-and-MATLAB/","excerpt":"Working with rodents in Jeffrey Erlich’s lab last summer, I found that rodent decision-making is so amazing. So, In the electronic design class in this semester, I tried to make a B-Pod system using FPGA and MATLAB by my own. However, I successful bulit up a trainning system, and tested on the real rodents. So I can use that to carry out my own rodent experiment in the future.","text":"Working with rodents in Jeffrey Erlich’s lab last summer, I found that rodent decision-making is so amazing. So, In the electronic design class in this semester, I tried to make a B-Pod system using FPGA and MATLAB by my own. However, I successful bulit up a trainning system, and tested on the real rodents. So I can use that to carry out my own rodent experiment in the future. I open-accessed all my code on Github, here is the LINK. About the BPODThe B-Pod system is developed by Joshua Sanders in his initial open research instruments (The BPOD r0.5) while completing his PhD in Kepecs Lab at Cold Spring Harbor Laboratory. Why BPODTraditional rodent behavior experiments such as water maze have many limitations.Althrough learning is involved in that task, however, we can not isolate the different level of cognitive process in that task, such as sensory processing, working memory retention or the formation of dicision making. The learning of such a traditional task is also simple. Also, we cannot study how the brain dealing with uncertainty in decision-making. To study different level of cognitive process in the rodent (Guo et al., 2014), the neural mechanism of learning the complex task (Liu et al., 2016), and to study how the brain dealing with stochastic (Tervo et al., 2014). We need a more powerful tools to generate sensory cue, and detect the animals’ behavior. That’s why we need the B-Pod system. More detailed examplesIf we want to study the working memory(WM) and the WM related decision making process in the rodent, the major method is to design a delay resonse task for the rodent. Such as auditory based(Erlich et al., 2011),whisker based(Guo et al., 2014), or visual based delay response task(Goard et al., 2016). In such a traditional delay response task, each trial contains about 3 phases. In the first phase, we give the subject a sensory cue (Such as a sound beep in a specific frequency, or a visual stimulus of a given directions or colors). Then there will be a delay period(Phase 2), the subject need to retent the information they got, and then(in phase 3), based on such information, make a specific behavior output(Such as poke to a specific port, lick/no lick or lick left/right) to gain water reward. Fig 1. Traditional working memory task for the rodent To study how the brain dealing with stochastic, we can give then uncertaint reward, and observe how the animals adjust their behaivour policy to maxinum the profit. And study the source to generate stochastic(ACC) and to dealing with uncertainty(OFC). (Tervo et al., 2014) Fig 2. How the brain dealing with stochastic Based on that, we need more powerful tools to train the animals to perform a decision-making involved complex task. That’s why I designed and made that device. Bacis idea of the BPOD systemThe basic idea of the bpod is to interact with the rodent using light or sound cue, and give them reward when they perform well. So the core problem is to detect rodents’ activity. Fig 3. We have several LEDs around the ports and the sound in the mouse box to ‘tell’ the animal ‘what to do’ To do so, we are using an IR emitter paired with an IR collector for each port. So everytime when the animal ‘poke’ into the port. The light from IR emitter will be block, so we can detect voltage change from the IR collector. Fig 4. We are using IR to detect animals’ behavior Using FPGA to control and monitering the devices.In my project, I’m using a FPGA(Field-Programmable Gate Array) to control the LEDs and water valve in the three mouse ports. Meanwhile, The FPGA is also used for monitering the IR collector of the three ports. Fig 5. The connection diagram of the firmware The FPGA is connected to the MAC computer via a serial-USB convert line. And the MATLAB is able to talk with the FPGA via this serial port. Once the IR system detect the mouse’s activity, the IR collector will sent signals to the FPGA. Then the FPGA will send an 8-bits information contains that information. The FPGA keeps contraling the LEDs and water valve. When the MATLAB want to change a state(For example, turn on/off the light, open the water). It will sent a 8-bits information via serial port to re-write the state vector in FPGA. FPGA then change the target voltage in it’s ports. Because the voltage of the IR system is 5V and the voltage of the FPGA is 3.3v, I passed the IR output to a voltage convertor and a 74HC14 to reverse the voltage. The it will be sent to the FPGA, 3.3v means a ‘block’ is there, and 0v means this port is clear. Fig 6. The connection diagram of the FPGA Connected all these firmware things. The FPGA, the LEDs, the IR ports, the 74HC14 chips and the computer, It looks like this. But it works pretty well. Fig 7. The testing firmware Using MATLAB to control the FPGA using FSMIn the computer, the MATLAB will generate a FSM(Finate State Meachine) based on the design of the experiment protocol to control the FPGA. The animals’ behavioul will trigger the stage switching. We define a class to describe the experiment protocol. The simplist version is called the ‘Operant’, in ‘Protocols/Operant’ path. It contains several sub-functions. init Section: Initialze the protocol, creating Sounds etc. useSetting Section: do some basic settings to the session. and load some old settings from previous experiment. PreparNextTrial Section: set the paramenters of the next trial based on prob. or history performance. RunTrial Section: Generate the FSM and run the trial. TrialComplete Section: do dome basic computation and analyze to this trial’s data. saveTrial section: save this trials data to the table. The dispatch.m in the modules path will call different parts of that class again and again. It also have many try-catch sentences, so that it will isolate bugs within each section and not affect running of the experiment. Also, I designed a subject management system there. We we input the subject’s id when starting the experiment, the program will record the stage and the information. So everthing will go automatically. Making the Rig BoxThe box was made by laser cutted Plexiglass. I drwan the sketch using AutoCAD. Fig 8. The sketch of the Rig Box And then we manufact the mouse poke port using 3D priting technique. Fig 9. the 3D model of the mouse port The hole is reserved for the IR LEDs and for the water tubes. Here is the fianl results after assembling. Fig 10. Assembled Rig box - front view Fig 11. Assembled Rig box - back view Before each run, we should manully test the rig system by calling rig_test function. In the future, I will make up a PCB version of the poke-wall system. To get more stable performance. The Basic Trainning ProtocolMy system contains a basic Protocol named ‘Operant’. It’s a very general protocol that can be used to train animals to associate lights or sounds with reward. To train the animals, we need to follow up a stage-to-stage procedure. The basic idea is shown below. In ‘Operant’, we have three stages. Fig 12. State diagram of the stage 1 First stage: ‘reward_train’. We will give them unconditional reward, just let them learn to drink. When they learnt how to drink, we will jump to the stage 2. Fig 13. State diagram of the stage 2Secound stage: ‘single_poke’. In this stage, we will turn the light of a port randomly, and wait for the animal to poke into that port. If they do well, they will get water reward, otherwise, they will hear about a short violation sound and no reward. When they got &gt;75% performance in the past 30 trials, they will go to the stage 3.# Running on Real RodentFig 14. Runninng test on real mouse After complete the whole things, I luckily found some mouse to conduct some real test. To make sure that my devices can detect real mouse’s behaviour and delivery reward water. Fig 15. The mouse is drinking on the BotC port after a successful trial When the mouse do poke during ITI peroid, they will recieve violation sound. Fig 16. The mouse went to TopL port during ITI The testing results reveal that our devices can robustly capture rodent’s poking behavior, give the cue and delivery reward water. The Next StepCurrerently, I’ve completed the trainning system. I’ll try to train several mouse and rats shortly after. References Tervo, D. G. R., Proskurin, M., Manakov, M., Kabra, M., Vollmer, A., Branson, K., &amp; Karpova, A. Y. (2014). Behavioral variability through stochastic choice and its gating by anterior cingulate cortex. Cell, 159(1), 21-32. doi:10.1016/j.cell.2014.08.037 Erlich, J. C., Bialek, M., &amp; Brody, C. D. (2011). A cortical substrate for memory-guided orienting in the rat. Neuron, 72(2), 330-343. doi:10.1016/j.neuron.2011.07.010 Liu, D., Gu, X., Zhu, J., Zhang, X., Han, Z., Yan, W., . . . Li, C. T. (2014). Medial prefrontal activity during delay period contributes to learning of a working memory task. Science, 346(6208), 458-463. doi:10.1126/science.1256573 Guo, Zengcai V., Li, N., Huber, D., Ophir, E., Gutnisky, D., Ting, Jonathan T., . . . Svoboda, K. (2014). Flow of Cortical Activity Underlying a Tactile Decision in Mice. Neuron, 81(1), 179-194. doi:10.1016/j.neuron.2013.10.020 Guo, Z. V., Inagaki, H. K., Daie, K., Druckmann, S., Gerfen, C. R., &amp; Svoboda, K. (2017). Maintenance of persistent activity in a frontal thalamocortical loop. Nature, 545(7653), 181-186. doi:10.1038/nature22324 Hanks, T. D., Kopec, C. D., Brunton, B. W., Duan, C. A., Erlich, J. C., &amp; Brody, C. D. (2015). Distinct relationships of parietal and prefrontal cortices to evidence accumulation. Nature, 520(7546), 220-223. doi:10.1038/nature14066 Goard, M. J., Pho, G. N., Woodson, J., &amp; Sur, M. (2016). Distinct roles of visual, parietal, and frontal motor cortices in memory-guided sensorimotor decisions. eLife, 5. doi:10.7554/eLife.13764","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"News","slug":"News","permalink":"http://www.jingjie.site/tags/News/"},{"name":"XJTU","slug":"XJTU","permalink":"http://www.jingjie.site/tags/XJTU/"},{"name":"Hardware","slug":"Hardware","permalink":"http://www.jingjie.site/tags/Hardware/"}]},{"title":"SURP in NYU Shanghai","slug":"SURP in NYU Shanghai","date":"2017-11-04T10:05:54.000Z","updated":"2017-12-08T14:02:25.000Z","comments":true,"path":"2017/11/04/SURP in NYU Shanghai/","link":"","permalink":"http://www.jingjie.site/2017/11/04/SURP in NYU Shanghai/","excerpt":"In the summer, I joined the SURP (Summer Undergraduate Research Program). Ran a 10-week research experience in NYU-ECNU institute for brain and cognitive sciences at NYU(New York University) Shanghai.","text":"In the summer, I joined the SURP (Summer Undergraduate Research Program). Ran a 10-week research experience in NYU-ECNU institute for brain and cognitive sciences at NYU(New York University) Shanghai. NYU’s News about me and the SURP:Nurturing Science Careers: NYU Shanghai’s Incubator for Future Neuroscientists Because my previous research in Visual Working memory, I was paired up with Dr. Jeffrey Erlich, Assistant Professor of Neural and Cognitive Sciences at NYU Shanghai for their shared interest in working memory. In this summer, I mainly focused on my own visual-working memory project. I stuided visual working memory(VWM) based decision making in the rodent. I quickly learned to program the state-of-the-art B-Pod behavioral training system developed by the lab, and I designed a 9-stage experiment protocol to train mice to perform a visual working-memory task. Mouse was performing the visual working memory task In the end, my advisor (Dr. Jeffrey Erlich) highly appraised my work. he said: I was really impressed by Jingjie’s dedication and skills. He made a real contribution during his summer in the lab’. (Shown in the NYU Shanghai Website) I was speaking at the SURP final presentation With Dr. Jeffrey C. Erlich in the lab In this project. I read several articles first to reasoning the hypothesis and then developed a protocol to train animals. In this entire project, I learn much about how to exactly running experiments on rodent using BPOD system, and how to work collaboratively using Git.","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"News","slug":"News","permalink":"http://www.jingjie.site/tags/News/"},{"name":"Summer Research","slug":"Summer-Research","permalink":"http://www.jingjie.site/tags/Summer-Research/"},{"name":"NYU","slug":"NYU","permalink":"http://www.jingjie.site/tags/NYU/"}]},{"title":"Build My Own REAL Bpod System","slug":"Build-my-own-REAL-Bpod-System","date":"2017-07-08T04:48:01.000Z","updated":"2018-07-20T00:59:45.000Z","comments":true,"path":"2017/07/08/Build-my-own-REAL-Bpod-System/","link":"","permalink":"http://www.jingjie.site/2017/07/08/Build-my-own-REAL-Bpod-System/","excerpt":"I’m a totally rodent behaviour guy now! To train my own mouse and rats, I tried to build my own bpod system in my home university(XJTU), in Prof.Changhe’s lab. I build a real bpod system, based on Joshua Sander’s preliminary design (Bpod r-0.5). This stuff can actually used for train the animals. I’m going to train my own rats and mouse for my own multi-sensory perceptual decision making task.","text":"I’m a totally rodent behaviour guy now! To train my own mouse and rats, I tried to build my own bpod system in my home university(XJTU), in Prof.Changhe’s lab. I build a real bpod system, based on Joshua Sander’s preliminary design (Bpod r-0.5). This stuff can actually used for train the animals. I’m going to train my own rats and mouse for my own multi-sensory perceptual decision making task. About BPOD and this workThe B-Pod system is developed by Joshua Sanders in his initial open research instruments (The BPOD r0.5) while completing his PhD in Kepecs Lab at Cold Spring Harbor Laboratory. This project is my first trial to make a real functional B-Pod, which I want to train my own animals. The introductions and overview of the B-Pod is covered in my previous post here. Building the hearware part of B-PodBuilding the rodent behvioural ports &amp; port breakout PCBBuilding the B-Pod arduino shield PCBBuilding the behavioural box","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"News","slug":"News","permalink":"http://www.jingjie.site/tags/News/"},{"name":"XJTU","slug":"XJTU","permalink":"http://www.jingjie.site/tags/XJTU/"},{"name":"Hardware","slug":"Hardware","permalink":"http://www.jingjie.site/tags/Hardware/"}]},{"title":"Design a ECG PPG measurement system","slug":"Design-a-ECG-PPG-measurement-system","date":"2017-07-08T04:48:01.000Z","updated":"2018-07-16T16:59:07.000Z","comments":true,"path":"2017/07/08/Design-a-ECG-PPG-measurement-system/","link":"","permalink":"http://www.jingjie.site/2017/07/08/Design-a-ECG-PPG-measurement-system/","excerpt":"As a BME student, how to build a ECG and SPO2(PPG) meachine is our core course. I definately need to do it well. In this project, I made a ECG SPO2 measurement system using TI(Texas Instruments)’s LDO chips, analog-front ICs, MSP430 MCU and Bluetooth module. I learnt a lot about how to drawing complex PCBs, how to use complex ICs, how to manage electric power, and practiced on doing MCU programming.","text":"As a BME student, how to build a ECG and SPO2(PPG) meachine is our core course. I definately need to do it well. In this project, I made a ECG SPO2 measurement system using TI(Texas Instruments)’s LDO chips, analog-front ICs, MSP430 MCU and Bluetooth module. I learnt a lot about how to drawing complex PCBs, how to use complex ICs, how to manage electric power, and practiced on doing MCU programming. About this projectThe B-Pod system is developed by Joshua Sanders in his initial open research instruments (The BPOD r0.5) while completing his PhD in Kepecs Lab at Cold Spring Harbor Laboratory. Why BPODTraditional rodent behavior experiments such as water maze have many limitations.Althrough learning is involved in that task, however, we can not isolate the different level of cognitive process in that task, such as sensory processing, working memory retention or the formation of dicision making. The learning of such a traditional task is also simple. Also, we cannot study how the brain dealing with uncertainty in decision-making. To study different level of cognitive process in the rodent (Guo et al., 2014), the neural mechanism of learning the complex task (Liu et al., 2016), and to study how the brain dealing with stochastic (Tervo et al., 2014). We need a more powerful tools to generate sensory cue, and detect the animals’ behavior. That’s why we need the B-Pod system. More detailed examplesIf we want to study the working memory(WM) and the WM related decision making process in the rodent, the major method is to design a delay resonse task for the rodent. Such as auditory based(Erlich et al., 2011),whisker based(Guo et al., 2014), or visual based delay response task(Goard et al., 2016). In such a traditional delay response task, each trial contains about 3 phases. In the first phase, we give the subject a sensory cue (Such as a sound beep in a specific frequency, or a visual stimulus of a given directions or colors). Then there will be a delay period(Phase 2), the subject need to retent the information they got, and then(in phase 3), based on such information, make a specific behavior output(Such as poke to a specific port, lick/no lick or lick left/right) to gain water reward. Fig 1. Traditional working memory task for the rodent To study how the brain dealing with stochastic, we can give then uncertaint reward, and observe how the animals adjust their behaivour policy to maxinum the profit. And study the source to generate stochastic(ACC) and to dealing with uncertainty(OFC). (Tervo et al., 2014) Fig 2. How the brain dealing with stochastic Based on that, we need more powerful tools to train the animals to perform a decision-making involved complex task. That’s why I designed and made that device. Bacis idea of the BPOD systemThe basic idea of the bpod is to interact with the rodent using light or sound cue, and give them reward when they perform well. So the core problem is to detect rodents’ activity. Fig 3. We have several LEDs around the ports and the sound in the mouse box to ‘tell’ the animal ‘what to do’ To do so, we are using an IR emitter paired with an IR collector for each port. So everytime when the animal ‘poke’ into the port. The light from IR emitter will be block, so we can detect voltage change from the IR collector. Fig 4. We are using IR to detect animals’ behavior Using FPGA to control and monitering the devices.In my project, I’m using a FPGA(Field-Programmable Gate Array) to control the LEDs and water valve in the three mouse ports. Meanwhile, The FPGA is also used for monitering the IR collector of the three ports. Fig 5. The connection diagram of the firmware The FPGA is connected to the MAC computer via a serial-USB convert line. And the MATLAB is able to talk with the FPGA via this serial port. Once the IR system detect the mouse’s activity, the IR collector will sent signals to the FPGA. Then the FPGA will send an 8-bits information contains that information. The FPGA keeps contraling the LEDs and water valve. When the MATLAB want to change a state(For example, turn on/off the light, open the water). It will sent a 8-bits information via serial port to re-write the state vector in FPGA. FPGA then change the target voltage in it’s ports. Because the voltage of the IR system is 5V and the voltage of the FPGA is 3.3v, I passed the IR output to a voltage convertor and a 74HC14 to reverse the voltage. The it will be sent to the FPGA, 3.3v means a ‘block’ is there, and 0v means this port is clear. Fig 6. The connection diagram of the FPGA Connected all these firmware things. The FPGA, the LEDs, the IR ports, the 74HC14 chips and the computer, It looks like this. But it works pretty well. Fig 7. The testing firmware Using MATLAB to control the FPGA using FSMIn the computer, the MATLAB will generate a FSM(Finate State Meachine) based on the design of the experiment protocol to control the FPGA. The animals’ behavioul will trigger the stage switching. We define a class to describe the experiment protocol. The simplist version is called the ‘Operant’, in ‘Protocols/Operant’ path. It contains several sub-functions. init Section: Initialze the protocol, creating Sounds etc. useSetting Section: do some basic settings to the session. and load some old settings from previous experiment. PreparNextTrial Section: set the paramenters of the next trial based on prob. or history performance. RunTrial Section: Generate the FSM and run the trial. TrialComplete Section: do dome basic computation and analyze to this trial’s data. saveTrial section: save this trials data to the table. The dispatch.m in the modules path will call different parts of that class again and again. It also have many try-catch sentences, so that it will isolate bugs within each section and not affect running of the experiment. Also, I designed a subject management system there. We we input the subject’s id when starting the experiment, the program will record the stage and the information. So everthing will go automatically. Making the Rig BoxThe box was made by laser cutted Plexiglass. I drwan the sketch using AutoCAD. Fig 8. The sketch of the Rig Box And then we manufact the mouse poke port using 3D priting technique. Fig 9. the 3D model of the mouse port The hole is reserved for the IR LEDs and for the water tubes. Here is the fianl results after assembling. Fig 10. Assembled Rig box - front view Fig 11. Assembled Rig box - back view Before each run, we should manully test the rig system by calling rig_test function. In the future, I will make up a PCB version of the poke-wall system. To get more stable performance. The Basic Trainning ProtocolMy system contains a basic Protocol named ‘Operant’. It’s a very general protocol that can be used to train animals to associate lights or sounds with reward. To train the animals, we need to follow up a stage-to-stage procedure. The basic idea is shown below. In ‘Operant’, we have three stages. Fig 12. State diagram of the stage 1 First stage: ‘reward_train’. We will give them unconditional reward, just let them learn to drink. When they learnt how to drink, we will jump to the stage 2. Fig 13. State diagram of the stage 2Secound stage: ‘single_poke’. In this stage, we will turn the light of a port randomly, and wait for the animal to poke into that port. If they do well, they will get water reward, otherwise, they will hear about a short violation sound and no reward. When they got &gt;75% performance in the past 30 trials, they will go to the stage 3.# Running on Real RodentFig 14. Runninng test on real mouse After complete the whole things, I luckily found some mouse to conduct some real test. To make sure that my devices can detect real mouse’s behaviour and delivery reward water. Fig 15. The mouse is drinking on the BotC port after a successful trial When the mouse do poke during ITI peroid, they will recieve violation sound. Fig 16. The mouse went to TopL port during ITI The testing results reveal that our devices can robustly capture rodent’s poking behavior, give the cue and delivery reward water. The Next StepCurrerently, I’ve completed the trainning system. I’ll try to train several mouse and rats shortly after. References Tervo, D. G. R., Proskurin, M., Manakov, M., Kabra, M., Vollmer, A., Branson, K., &amp; Karpova, A. Y. (2014). Behavioral variability through stochastic choice and its gating by anterior cingulate cortex. Cell, 159(1), 21-32. doi:10.1016/j.cell.2014.08.037 Erlich, J. C., Bialek, M., &amp; Brody, C. D. (2011). A cortical substrate for memory-guided orienting in the rat. Neuron, 72(2), 330-343. doi:10.1016/j.neuron.2011.07.010 Liu, D., Gu, X., Zhu, J., Zhang, X., Han, Z., Yan, W., . . . Li, C. T. (2014). Medial prefrontal activity during delay period contributes to learning of a working memory task. Science, 346(6208), 458-463. doi:10.1126/science.1256573 Guo, Zengcai V., Li, N., Huber, D., Ophir, E., Gutnisky, D., Ting, Jonathan T., . . . Svoboda, K. (2014). Flow of Cortical Activity Underlying a Tactile Decision in Mice. Neuron, 81(1), 179-194. doi:10.1016/j.neuron.2013.10.020 Guo, Z. V., Inagaki, H. K., Daie, K., Druckmann, S., Gerfen, C. R., &amp; Svoboda, K. (2017). Maintenance of persistent activity in a frontal thalamocortical loop. Nature, 545(7653), 181-186. doi:10.1038/nature22324 Hanks, T. D., Kopec, C. D., Brunton, B. W., Duan, C. A., Erlich, J. C., &amp; Brody, C. D. (2015). Distinct relationships of parietal and prefrontal cortices to evidence accumulation. Nature, 520(7546), 220-223. doi:10.1038/nature14066 Goard, M. J., Pho, G. N., Woodson, J., &amp; Sur, M. (2016). Distinct roles of visual, parietal, and frontal motor cortices in memory-guided sensorimotor decisions. eLife, 5. doi:10.7554/eLife.13764","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"News","slug":"News","permalink":"http://www.jingjie.site/tags/News/"},{"name":"XJTU","slug":"XJTU","permalink":"http://www.jingjie.site/tags/XJTU/"},{"name":"Hardware","slug":"Hardware","permalink":"http://www.jingjie.site/tags/Hardware/"}]},{"title":"Present My Work in VSS 2017","slug":"gotovss","date":"2017-05-30T09:20:14.000Z","updated":"2017-09-23T12:31:45.000Z","comments":true,"path":"2017/05/30/gotovss/","link":"","permalink":"http://www.jingjie.site/2017/05/30/gotovss/","excerpt":"Few days ago, I attended VSS 2017 conference in St. Pete Beach. And presented my work in poster.","text":"Few days ago, I attended VSS 2017 conference in St. Pete Beach. And presented my work in poster. Here is my poster presentation. And a online-version of my Poster. If you are interested about my work. Please contact me directly via jingjie.li@nyu.edu or jingjie.li@stu.xjtu.edu.cn","raw":null,"content":null,"categories":[{"name":"Publications","slug":"Publications","permalink":"http://www.jingjie.site/categories/Publications/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"News","slug":"News","permalink":"http://www.jingjie.site/tags/News/"},{"name":"Publications","slug":"Publications","permalink":"http://www.jingjie.site/tags/Publications/"},{"name":"VSS","slug":"VSS","permalink":"http://www.jingjie.site/tags/VSS/"}]},{"title":"Courses I've taken (MOOC)","slug":"courses","date":"2017-02-15T07:52:25.000Z","updated":"2018-12-17T14:29:19.000Z","comments":true,"path":"2017/02/15/courses/","link":"","permalink":"http://www.jingjie.site/2017/02/15/courses/","excerpt":"As cognitive neuroscience a interdisciplinary subject, we need some other skills and knowledge in order to carry out research in this field such like math and programming etc.\nIn order to strengthen my programming skills and gain some knowledge about other interdisciplinary subjects(Data Science, Meachine Learning). I took several online courses(MOOCs), mainly in Coursea.org.","text":"As cognitive neuroscience a interdisciplinary subject, we need some other skills and knowledge in order to carry out research in this field such like math and programming etc. In order to strengthen my programming skills and gain some knowledge about other interdisciplinary subjects(Data Science, Meachine Learning). I took several online courses(MOOCs), mainly in Coursea.org. Moocs I’ve TakenCourses List(The courses I’ve taken in school was recorded in my Transcript). MOOCs are listed below. Introduction to Programming with MATLAB Meachine Learning Principles of fMRI 1 Neural Networks for Machine Learning Introduction to Programming with MATLAB — 07 2015-09 2015After graduate from high school, I took this course in the up-coming summer vocation in order to improve my programming skills about MATLAB. This course benefit me a lot for my further study and research with MATLAB. Certification Meachine Learning (By Andrew Ng) — 09 2015-11 2015I then took this course in the first semester of freshman. In this course, I got basic understanding about what meachine learning algorithms do. I realized several algorithms using MATLAB, including Liner Regression, Logestic Regression, Feed Forward Neural Network, SVM, PCA, K-means, Collaborative filtering etc. After this course, I acquired the ability to running simple meachine learning algorithms using MATLAB. That lay a foundation for my further study about MVPA, Encoding Models and Behavioral Modeling. Certification Principles of fMRI 1 — 09 2015-11 2015In spring semester in 2016 , I took this course for gaining some basic understanding about fMRI. In this course, I studied some basic knowledge about fMRI and fMRI data analyze. Mainly about several points: 1)fMRI Data Structure, 2)Basic MR Physics and imaging, 3)Signal, Noise, and BOLD Physiology,4)fMRI Experiment Design,5)Pre-Processing of fMRI Data,6)GLM univariate analyze and t-contrast Also, I together with several other friends who is also interested in this field made a Chinese version note of this class for learns in China not good at English. We posted it in Zhihu. Our article has gathered about 260 up-votes and have influenced a lot of people. Neural Networks for Machine Learning — 10 2016-02 2017In fall semester in 2016, I took this course for gaining more understanding about meachine learning, particularly about (deep) neural networks. I learnt about Perceptron, Feed Forward Neural Networ, RBM, Deep Belief Nets, and auto encoders etc. Most importently, I got to know about how to train a deep neural network using unsuperviced learning with pre-trainning processing. I also realized that the learning rules of RBM and DBN share some same point with LTDP in our neural system. This course provide me with not only skills and knowledge about neual network ,also inspire me to do some futher thinking about the relationship between meachine learning and neuroscience. Certification","raw":null,"content":null,"categories":[{"name":"Study Experience","slug":"Study-Experience","permalink":"http://www.jingjie.site/categories/Study-Experience/"}],"tags":[{"name":"Me","slug":"Me","permalink":"http://www.jingjie.site/tags/Me/"},{"name":"Courses","slug":"Courses","permalink":"http://www.jingjie.site/tags/Courses/"},{"name":"MOOCs","slug":"MOOCs","permalink":"http://www.jingjie.site/tags/MOOCs/"}]},{"title":"A summer in PKU, A summer in Fang's lab","slug":"A_summer_in_PKU","date":"2016-08-22T05:31:28.000Z","updated":"2018-12-17T14:19:06.000Z","comments":true,"path":"2016/08/22/A_summer_in_PKU/","link":"","permalink":"http://www.jingjie.site/2016/08/22/A_summer_in_PKU/","excerpt":"In the summer vocation in 2016 (After my freshman year in the university). I spent a whole summer in the Peking University(PKU). I attended the neuroscience summer school in the first week. After that, I emailed Prof Fang Fang for a chance to study more. I then stayed in prof. Fang Fang’s lab as a summer research intern for the up-coming 5 weeks.\n6 Weeks in PKU was very meaninful. The lectures in the summer school expand my horizeon greatly. 5 weeks in Fang’s lab tought my a lot about how a graduate student in cognitive neuroscience reasons and works.","text":"In the summer vocation in 2016 (After my freshman year in the university). I spent a whole summer in the Peking University(PKU). I attended the neuroscience summer school in the first week. After that, I emailed Prof Fang Fang for a chance to study more. I then stayed in prof. Fang Fang’s lab as a summer research intern for the up-coming 5 weeks. 6 Weeks in PKU was very meaninful. The lectures in the summer school expand my horizeon greatly. 5 weeks in Fang’s lab tought my a lot about how a graduate student in cognitive neuroscience reasons and works. In Fang’s lab. I mainly did these stuff below. Running my own psychophysical experimentsI learnt about programing using PTB(Psychtoolbox) in MATLAB. I carried out a preliminary experiment to study how a prior unambigious Structure-from-motion(SFM) effects the up-coming bistable SFM. Figure 1. Carrying my own psychophysics experiments The psychophysical protocol is here. Figure 2. The psychophysical protocol of my experiment Then I fitted a psychophysical curve to quantify this influence. Dealing with fMRI raw dataI studied how to use SPM12 to process and manipulate fMRI data using a fMRI data set used for trainning that a graduate gave me. By going though a lot of tutorials and documents, I realized a lot of data-processing procesures such like Slice-timing correction, Motion Correction, Co-registration, Spacial Normalization, Spatial Smoothing and uni-variation GLM analyze. Figure shown below. Figure 3. Processing fMRI raw data using SPM 12 Moreover, I carried out an ROI analyze using SPM plug-in tools such like XjView and MarsBar. I ploted a BSC(Bold Signal Change) in MT+ result, shown below. Figure 4. Bold signal change percentage in MT+ Reasoning and thinking like a graduate studentSpend 5 weeks in Dr. Fang’s lab benifited me a lot. I got familiar with the graduate students in fang’s lab, understood what they did and how they thought, read more research articles based on their suggestions, and tried to carry my own experiments. The experience I had there stimulated me to think, to try and to act. It refreshed my plan about what to do in the future. Without this experience, I cannot carry my own research project in the following semester. Thank you professor fang fang, and all lab members in Dr. fang’s lab.","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"},{"name":"Study Experience","slug":"Research-Experience/Study-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/Study-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"PKU","slug":"PKU","permalink":"http://www.jingjie.site/tags/PKU/"},{"name":"fMRI","slug":"fMRI","permalink":"http://www.jingjie.site/tags/fMRI/"},{"name":"Psychophysics","slug":"Psychophysics","permalink":"http://www.jingjie.site/tags/Psychophysics/"},{"name":"Summer School","slug":"Summer-School","permalink":"http://www.jingjie.site/tags/Summer-School/"}]},{"title":"Nature image identification and voxels activity modeling using fMRI encoding model","slug":"nature-image-identification","date":"2016-06-14T07:47:18.000Z","updated":"2017-09-23T12:26:06.000Z","comments":true,"path":"2016/06/14/nature-image-identification/","link":"","permalink":"http://www.jingjie.site/2016/06/14/nature-image-identification/","excerpt":"In may,2016. I tried to repeat a pioneering research published on NATURE (Kay et al., 2008), using a data-driven Voxel-Wise Model (Naselaris et al., 2011), I successfully constructed a liner receptive field model for every voxels using the Gabor wavelet filter according to the encoding theory of the primary visual cortex (Hubel and Wiesel, 1968), without noise ceiling procedures I also got remarkable accuracy in the identification task (about 48.8%, meanwhile the chance level is about 0.8%).\nMy code is now open sccess on Github  -  Voxels-activity-modeling-using-fMRI-data.","text":"In may,2016. I tried to repeat a pioneering research published on NATURE (Kay et al., 2008), using a data-driven Voxel-Wise Model (Naselaris et al., 2011), I successfully constructed a liner receptive field model for every voxels using the Gabor wavelet filter according to the encoding theory of the primary visual cortex (Hubel and Wiesel, 1968), without noise ceiling procedures I also got remarkable accuracy in the identification task (about 48.8%, meanwhile the chance level is about 0.8%). My code is now open sccess on Github - Voxels-activity-modeling-using-fMRI-data. About the OPEN ACCESS dataThe data comes from CRCNS - Collaborative Research in Computational . Data set: Kay, K.N.; Naselaris, T.; Gallant, J. (2011): fMRI of human visual areas in response to natural images. CRCNS.org.http://dx.doi.org/10.6080/K0QN64NG Stimulus Figure 1. A given example of the natural image stimulus Subjects view 1870 images while recording their brain activities using fMRI. 1750 of these are for training, the remaining is the test set. After the pre-processing procedure. They used GLM to estimate response for every images. Then they choose about 25000 voxels from (V1, V2, V3, V3a, V3b, V4, LatOcc etc.). MethodOverview Figure 2. The overview of the data processing procedures. Mainly in three parts, feature extractions, voxels selection, and main training stage. In order to modeling voxels’ tunning dynamic. We use this three-stage method. Including feature extractions, voxels selection, and main training(modeling)stage. Procedures &amp; ResultsExtract featuresAccording the theory of the encoding mechanism of the early visual cortex (EVC). Neurons in EVC firing for some particular orientation and spatial frequency in a particular visual position, which we called the receptive field. In fMRI, the activity patterns in the human visual cortex can also reveal what stimulus orientation a person is viewing(Kamitani &amp; Tong, 2005). To pick up infomation of orientation and spatial frequency in a natural image. We using the garbor wavelet to project onto every images in different space location, orientation, and spatial frequency, which we called the Gabor wavelet pyramid. As for the Gabor wavelet pyramid. Wavelets occur at five (or, in some cases, six) spatial frequencies. This panel depicts one wavelet at each of the first five spatial frequencies. At each spatial frequency f cycles per field-of-view (FOV), wavelets are positioned on an f × f grid, as indicated by the translucent lines.Orientation and phase. At each grid position, wavelets occur at eight orientations and two phases. This panel depicts a complete set of wavelets for a single grid position. Dashed lines indicate the bounds of the mask associated with each wavelet.(Kay et al., 2008) Showed below. Figure 3. Gabor wavelet pyramid design. There are five different spatial frequency(1,2,4,8,16 FOV). For every single spatial frequency, it has (1,4,16,64,256) types of different position in the visual field. For every position, there are 2 orthogonal phase and 8 different angles(0:22.5:157.5). Together, there are 5456 different gabor wavelets in the Gabor wavelet pyramid. I used the gabor_fn.m function to produce a gabor wavelet for the given sf,angle,phase,posi. from Wikipedia Then, I wrote a function gaborfit.m to produce a set of gabor wavelet image directlly. It produce a martix called gab(128x128x5456).Represent 5456 different gabor wavelet image(128x128). To compute the projection. I wrote compscript.m (section 1). To compute the projection of 5456 wavelets for 1750 images. The projections for each quadrature pair of wavelets are then squared, summed, and square-rooted, yielding a measure of contrast energy. The result will be in the martix called proj(1750x2728). To remove wavelets ouuside the field of the natural images(outside the circle). I wrote a function called gabdelete in gabdelete.m. The result will be in the martix called projdeleteedge(1750x2728). Training algorithm Figure 4. Gabor wavelet pyramid model.. Here we use multi-variation liner regression to build up the model. Using the features which we cauculated before using gabor wavelet pyramid model. We use the tronditional square-root error cost function, and using gradient descent with monument to optimize the cost function. $h=h- \\varepsilon g$ $g=\\left[ \\left[ X’(Xh-y) \\right]+\\alpha g \\right]$ To prevent over-fitting, we used early stopping. A randomly selected 20% of the data-set were removed and kept as a stopping set. Iterations proceeded until the squared error on the stopping set nolonger decreased, or until the squared error on the training set no longer decreased. I wrote two function to running this regression. inittrain.m and linereg.m The initrain.m is used to pre-processing the dataset, devided it into training set and stopping set for early stopping, and remove NaN data points. The linereg.m is used for running the optimzation of the cost function. Pre-training stageTrainning that models for 25000 voxels is too time-consuming. In order to improve efficiency. We carry a pre-training stage. In order to accelerate the training speed, we tried to reduce dimensions firstly. We did not take orentation into consideration: we averged the 8 gabor wavelet projection for each position. Then we can use that new features to fit the model. Using the weight for every location we can reconstruct the population receptive field. This method is pretty likely to build up a data driven pRF(population receptive field). Figure 5. A given example of the reconstructed pRF. Left img represent a well-fitted voxel, it’s receptive field is very consentrate and sparse. Image in right represent a traditional poorly fitted voxel, it’s receptive field is very confusion. I worte _gaborfield.m to generate a field map using gaussian functions.The RFvis.m is used for reconstructing a population receptive field map for a given voxels, using the weight computed in the pre-trainning stage and the gabor_field.m, sum it up to form a receptive field map.We need to remove those poorly fitted voxels. We have two ways to select voxels. 1. Gaussian FittedWe can using Gaussian function to fitted the reconstructed pRF. The Gaussian RMS width(field vaule in fig 5.) can represent the ‘goodness of fit’, but sometimes some poorly-fitted can also be selected because of some overfitting problem. 2. R-Squared sortingTo quantify the ‘goodness of fit’. We can also using R-Squared vaule directly. We cauculate R2 of those 25000 voxels and make a sorting. And we can choose the top 500 voxels to do the futher analyze. After the R-Squared sorting procedure, the top-10 voxels showed below. Figure 5. Top 10 well-fitted voxels. Figure shows the reconstructed pRF of top 10 well-fitted voxels, it’s all has a relatively ‘sparse’ receptive field The anatomical distribution of those 500 voxels showed below. Figure 6. The anatomical distribution of those 500 voxels. As we can see, a huge amount of voxels are from early visual cortex(V1,V2,V3). I wrote causelectedh.m to select 500 voxels, and further more, to run the main-trainning stage below. Main-training stageHave choosen 500 well-fitted voxels. We fitted those voxels with full features(with 8 orientations).I then use this model to predict 500 voxels activities based on 120 natural images in the test set(120 images).Then, We compute R-Squared vaule between actually response value and the predicted vaule of those 500 voxels among those 120 images, using that to generate a 120x120 image. Figure 6. The correlation map of the actually response value and the predicted vaule of those 500 voxels. The (i,j)position’s color represent the R-Squared vaule between actually response value of the number i th image and the predicted vaule of the j th image of those 500 voxels. I wrote corxcmp.m to predict the activity using test set images, and generate this final result. In the identifation task. We re-match the target’s brain activities with the best correlated predicted brain activities. In my work, without noise ceiling procedures, the identifation performance is about 58.8%, meanwhile, the chance level is about 0.83%. Using the optimized wights in the main-training stage. We could generate a tuning properties image. It could tell us which orinentation and spatial frequency contribute more to the activity of the voxels. As a given example, for the No.23198 voxel, we visualize the weight distribution of the 8 orintations and 5 spatial frequency (5x8). Figure 7. The weight distribution of the 8 orintation and 5 spatial frequency for the voxel 23198. . Further more, we plot the tuning properties for the orintations separately. Figure 8.The tuning properties for the orintations(L) and spatial frequency(R). . We can observe that, this voxel prefer 45 degres, and relevantly prefer higher special frequency. Consist with the encoding theory of the early visual cortex. ReferencesGilbert, C. D., &amp; Wiesel, T. N. (1985). Intrinsic connectivity and receptive field properties in visual cortex. Vision research, 25(3), 365-374. Chen, N., P. Cai, T. Zhou, B. Thompson, and F. Fang. 2016. ‘Perceptual learning modifies the functional specializations of visual cortical areas’, Proc Natl Acad Sci U S A. Hubel, D. H., and T. N. Wiesel. 1968. ‘Receptive fields and functional architecture of monkey striate cortex’, Journal of Physiology, 195: 215-43. Huth, A. G., W. A. de Heer, T. L. Griffiths, F. E. Theunissen, and J. L. Gallant. 2016. ‘Natural speech reveals the semantic maps that tile human cerebral cortex’, Nature, 532: 453-8. Kandel, E., and J. Schwartz. 2013. Principles of Neural Science, Fifth Edition (McGraw-Hill Education). Kay, K. N., T. Naselaris, R. J. Prenger, and J. L. Gallant. 2008. ‘Identifying natural images from human brain activity’, Nature, 452: 352-5. Miyawaki, Y., H. Uchida, O. Yamashita, M. A. Sato, Y. Morito, H. C. Tanabe, N. Sadato, and Y. Kamitani. 2008. ‘Visual image reconstruction from human brain activity using a combination of multiscale local image decoders’, Neuron, 60: 915-29. Naselaris, T., K. N. Kay, S. Nishimoto, and J. L. Gallant. 2011. ‘Encoding and decoding in fMRI’, NeuroImage, 56: 400-10. Norman, K. A., S. M. Polyn, G. J. Detre, and J. V. Haxby. 2006. ‘Beyond mind-reading: multi-voxel pattern analysis of fMRI data’, Trends Cogn Sci, 10: 424-30. Sprague, T. C., &amp; Serences, J. T. (2013). Attention modulates spatial priority maps in the human occipital, parietal and frontal cortices. Nat Neurosci, 16(12), 1879-1887. doi:10.1038/nn.3574","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"fMRI","slug":"fMRI","permalink":"http://www.jingjie.site/tags/fMRI/"},{"name":"XJTU","slug":"XJTU","permalink":"http://www.jingjie.site/tags/XJTU/"},{"name":"MATLAB","slug":"MATLAB","permalink":"http://www.jingjie.site/tags/MATLAB/"},{"name":"Repetation","slug":"Repetation","permalink":"http://www.jingjie.site/tags/Repetation/"},{"name":"encoding model","slug":"encoding-model","permalink":"http://www.jingjie.site/tags/encoding-model/"}]},{"title":"Visual Image Reconstruction using fMRI","slug":"visual_image_reconstruction","date":"2016-03-09T18:19:55.000Z","updated":"2017-09-22T16:37:54.000Z","comments":true,"path":"2016/03/10/visual_image_reconstruction/","link":"","permalink":"http://www.jingjie.site/2016/03/10/visual_image_reconstruction/","excerpt":"Mind-reading is really amazing and exciting. Using modern fMRI(functional magnetic resonance imaging) technique. We can now decoding some infomation from participant’s brain activities. \nBased on that, I repeated some previous research in Badong Chen’s lab, such as decode fMRI signal from primary visual cortex (V1) and reconstruct pattern image from fMRI signal (Miyawaki et al., 2008). Meanwhile, I improved the accuracy of the reconstruction by about 4% (from about 80% to about 84%), using the improved MVPA method with SVM classifier (Norman et al., 2006).","text":"Mind-reading is really amazing and exciting. Using modern fMRI(functional magnetic resonance imaging) technique. We can now decoding some infomation from participant’s brain activities. Based on that, I repeated some previous research in Badong Chen’s lab, such as decode fMRI signal from primary visual cortex (V1) and reconstruct pattern image from fMRI signal (Miyawaki et al., 2008). Meanwhile, I improved the accuracy of the reconstruction by about 4% (from about 80% to about 84%), using the improved MVPA method with SVM classifier (Norman et al., 2006). IntroductionMind-reading is really amazing and exciting. Using modern fMRI(functional magnetic resonance imaging) technique. We can now decoding some infomation from participant’s brain activities. Based on that, I repeated some previous research in Badong Chen’s lab, such as decode fMRI signal from primary visual cortex (V1) and reconstruct pattern image from fMRI signal (Miyawaki et al., 2008). Meanwhile, I improved the accuracy of the reconstruction by about 4% (from about 80% to about 84%), using the improved MVPA method with SVM classifier (Norman et al., 2006). This article is only a berif introduction of my work. You can contact me for the reconstruction result video demo, for the source code and for more detail. ResultsSubjects view 12x12 binary(Black or White) pixels images while recoding their brain activities using fMRI. 352 of which are in random. 80s are in regular (The pattern of them are like numbers, etc.), see figure below. Figure 1. Left binary image is in random, right is in regular Then we use GLM procedures to modeling brain activity for every stimuli. Firstly, I use MVPA(Multi-Voxels pattern analyze) to build up a model for every pixel (1x1 scale). We then everaged the vaule of 2 neighbouring pixels vertically (2x1 scale) and horizentally (1x2 scale), and 4 neighbouring pixels (2x2 scale). Figure showed below.(Miyawaki et al., 2008) Figure 2. Multi-scale local image bases for buliding MVPA model In MVPA, I firstly choosed 3037 voxels from V1, then caculated Pearson’s r for each voxels. Then sort them using r vaule. We choose the 50 voxels from it(top 30 and last 20). Then we trainning a SVM classifier to build up the MVPA model using 352 random images as a trainning set. The code example showed below. 1function [ SVMStruct,corvox ] = singlevoxtrai(trainingsetnum,posi,beta,stim) %This model train a SVM model to a given posi of the stim % trainingsetnum=1:176; % posi=[6,6]; %% section a,trainnning one single voxal trainingset=beta(:,trainingsetnum); [~,selectvox,~] = voxcor(posi(1,1),posi(1,2),stim(:,:,... trainingsetnum),trainingset);%select the corresponding voxels of the stim Training=beta(selectvox,trainingsetnum)'; Group=reshape(stim(posi(1,1),posi(1,2),:),size(stim,3),1); Group=Group(trainingsetnum,:); SVMStruct = svmtrain(Training,Group,'kernel_function','polynomial'); corvox=selectvox; end Then we use the remaining 80 examples to test our model, using the MVPA models we trainned before, to compute the pixels’ vaule given brain activities. Repeat these procedures to every pixels in 4 scale. After combining 4 scale using liner regression for each pixels. Finally, we got a reconstructed image using subject’s brain activities. We compute deviation using reconstruced image and the actually image (square-root error). The example show below. Figure 3. The demo video of the reconstructed image This article is only a berif introduction of my work. You can contact me for the reconstruction result video demo, for the source code and for more detail. References Miyawaki, Yoichi, et al. “Visual image reconstruction from human brain activity using a combination of multiscale local image decoders..” Neuron60.5(2008):915-29. Norman, K. A et al.,(2006). Beyond mind-reading: multi-voxel pattern analysis of fMRI data. Trends Cogn Sci, 10(9), 424-430. doi:10.1016/j.tics.2006.07.005","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"fMRI","slug":"fMRI","permalink":"http://www.jingjie.site/tags/fMRI/"},{"name":"XJTU","slug":"XJTU","permalink":"http://www.jingjie.site/tags/XJTU/"},{"name":"MVPA","slug":"MVPA","permalink":"http://www.jingjie.site/tags/MVPA/"},{"name":"MATLAB","slug":"MATLAB","permalink":"http://www.jingjie.site/tags/MATLAB/"},{"name":"Repetation","slug":"Repetation","permalink":"http://www.jingjie.site/tags/Repetation/"}]}]}
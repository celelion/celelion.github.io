<!DOCTYPE html>
<html lang="en">
<head>

    <!--[if lt IE 9]>
        <style>body {display: none; background: none !important} </style>
        <meta http-equiv="Refresh" Content="0; url=//outdatedbrowser.com/" />
    <![endif]-->

<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge, chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
<meta name="format-detection" content="telephone=no" />
<meta name="author" content="Jingjie Li" />



<meta name="description" content="In may,2016. I tried to repeat a pioneering research published on NATURE (Kay et al., 2008), using a data-driven Voxel-Wise Model (Naselaris et al., 2011), I successfully constructed a liner receptive">
<meta property="og:type" content="article">
<meta property="og:title" content="Nature image identification and voxels activity modeling using fMRI encoding model">
<meta property="og:url" content="http://www.jingjie.site/2016/06/14/nature-image-identification/index.html">
<meta property="og:site_name" content="JingjieLi’s Brain">
<meta property="og:description" content="In may,2016. I tried to repeat a pioneering research published on NATURE (Kay et al., 2008), using a data-driven Voxel-Wise Model (Naselaris et al., 2011), I successfully constructed a liner receptive">
<meta property="og:image" content="http://i1.piimg.com/4851/704e84210b37d372.png">
<meta property="og:image" content="http://i1.piimg.com/4851/98d7f6aff9de2bf3.png">
<meta property="og:image" content="http://i1.piimg.com/4851/dc03fc9a075abd7d.png">
<meta property="og:image" content="http://p1.bpimg.com/4851/2ffdb90439b274fd.png">
<meta property="og:image" content="http://p1.bpimg.com/4851/5bd832ebd9427c9f.png">
<meta property="og:image" content="http://p1.bpimg.com/4851/69189a49aa9fd58b.jpg">
<meta property="og:image" content="http://p1.bqimg.com/4851/2d56f0879a6c869c.jpg">
<meta property="og:image" content="http://p1.bpimg.com/4851/5ea10a33ac4cf3bc.jpg">
<meta property="og:image" content="http://p1.bqimg.com/4851/7c3e2d670fa3c75c.png">
<meta property="og:image" content="http://p1.bqimg.com/4851/dfeb524e2f63586f.png">
<meta property="og:updated_time" content="2017-01-31T13:28:33.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Nature image identification and voxels activity modeling using fMRI encoding model">
<meta name="twitter:description" content="In may,2016. I tried to repeat a pioneering research published on NATURE (Kay et al., 2008), using a data-driven Voxel-Wise Model (Naselaris et al., 2011), I successfully constructed a liner receptive">
<meta name="twitter:image" content="http://i1.piimg.com/4851/704e84210b37d372.png">

<link rel="apple-touch-icon" href= "/apple-touch-icon.png">


    <link rel="alternate" href="/atom.xml" title="JingjieLi’s Brain" type="application/atom+xml">



    <link rel="shortcut icon" href="/favicon.png">



    <link href="//cdn.bootcss.com/animate.css/3.5.1/animate.min.css" rel="stylesheet">



    <link href="//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.css" rel="stylesheet">



    <script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
    <link href="//cdn.bootcss.com/pace/1.0.2/themes/blue/pace-theme-minimal.css" rel="stylesheet">


<link rel="stylesheet" href="/css/style.css">



<link href="//cdn.bootcss.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet">


<title>Nature image identification and voxels activity modeling using fMRI encoding model | JingjieLi’s Brain</title>

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="//cdn.bootcss.com/clipboard.js/1.5.10/clipboard.min.js"></script>

<script>
    var yiliaConfig = {
        fancybox: true,
        animate: true,
        isHome: false,
        isPost: true,
        isArchive: false,
        isTag: false,
        isCategory: false,
        fancybox_js: "//cdn.bootcss.com/fancybox/2.1.5/jquery.fancybox.min.js",
        scrollreveal: "//cdn.bootcss.com/scrollReveal.js/3.1.4/scrollreveal.min.js",
        search: true
    }
</script>


    <script> yiliaConfig.jquery_ui = [false]; </script>



    <script> yiliaConfig.rootUrl = "\/";</script>






</head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        <a href="/" class="profilepic">
            <img src="/img/avatar.png" class="animated zoomIn">
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Jingjie Li</a></h1>
        </hgroup>

        
        <p class="header-subtitle">A sophomore from Xi’an Jiaotong University(XJTU)</p>
        

        
            <form id="search-form">
            <input type="text" id="local-search-input" name="q" placeholder="search..." class="search form-control" autocomplete="off" autocorrect="off" searchonload="false" />
            <i class="fa fa-times" onclick="resetSearch()"></i>
            </form>
            <div id="local-search-result"></div>
            <p class='no-result'>No results found <i class='fa fa-spinner fa-pulse'></i></p>
        


        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                    </div>
                    
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>Menu</li>
                        <li>Tags</li>
                        
                        <li>Friends</li>
                        
                        
                    </ul>
                </div>
            </div>
        

        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a href="/">Home</a></li>
                        
                            <li><a href="/archives/">Archives</a></li>
                        
                            <li><a href="/tags/">Tags</a></li>
                        
                            <li><a href="/about/">About</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" href="mailto:jingjie.li@stu.xjtu.edu.cn" title="Email"></a>
                            
                                <a class="fa GitHub" href="https://github.com/celelion" title="GitHub"></a>
                            
                                <a class="fa 知乎" href="https://www.zhihu.com/people/jingjie.li/answers" title="知乎"></a>
                            
                        </ul>
                    </nav>
                </section>
                
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/MATLAB/">MATLAB</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MVPA/">MVPA</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Me/">Me</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/News/">News</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/PKU/">PKU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Psychophysics/">Psychophysics</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Publications/">Publications</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Repetation/">Repetation</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Scholar/">Scholar</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/Summer-School/">Summer School</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XJTU/">XJTU</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/encoding-model/">encoding model</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/fMRI/">fMRI</a></li></ul>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    
                      <a class="main-nav-link switch-friends-link" href="http://www.xjtu.edu.cn/">Xi’an Jiaotong University(XJTU)</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://www.pku.edu.cn/">Peking University(PKU)</a>
                    
                      <a class="main-nav-link switch-friends-link" href="http://gr.xjtu.edu.cn/web/chenbd/home">Chen,Badong</a>
                    
                      <a class="main-nav-link switch-friends-link" href="https://www.psy.pku.edu.cn/faculty.php?fid=36">Fang Fang</a>
                    
                    </div>
                </section>
                

                
            </div>
        </div>
    </header>                
</div>
    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Jingjie Li</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                <img src="/img/avatar.png" class="animated zoomIn">
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Jingjie Li</a></h1>
            </hgroup>
            
            <p class="header-subtitle">A sophomore from Xi’an Jiaotong University(XJTU)</p>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/">Home</a></li>
                
                    <li><a href="/archives/">Archives</a></li>
                
                    <li><a href="/tags/">Tags</a></li>
                
                    <li><a href="/about/">About</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fa Email" target="_blank" href="mailto:jingjie.li@stu.xjtu.edu.cn" title="Email"></a>
                            
                                <a class="fa GitHub" target="_blank" href="https://github.com/celelion" title="GitHub"></a>
                            
                                <a class="fa 知乎" target="_blank" href="https://www.zhihu.com/people/jingjie.li/answers" title="知乎"></a>
                            
                        </ul>
            </nav>
        </header>                
    </div>
    <link class="menu-list" tags="Tags" friends="Friends" about="About Me"/>
</nav>
      <div class="body-wrap"><article id="post-nature-image-identification" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/06/14/nature-image-identification/" class="article-date">
      <time datetime="2016-06-14T07:47:18.000Z" itemprop="datePublished">2016-06-14</time>
</a>


    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Nature image identification and voxels activity modeling using fMRI encoding model
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/Research-Experience/">Research Experience</a>
    </div>


        
    <div class="article-tag tagcloud">
        <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MATLAB/">MATLAB</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Repetation/">Repetation</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Scholar/">Scholar</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/XJTU/">XJTU</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/encoding-model/">encoding model</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/fMRI/">fMRI</a></li></ul>
    </div>

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <p>In may,2016. I tried to repeat a pioneering research published on <em>NATURE</em> (Kay et al., 2008), using a data-driven <em>Voxel-Wise</em> Model (Naselaris et al., 2011), I successfully constructed a liner receptive field model for every voxels using the Gabor wavelet filter according to the encoding theory of the primary visual cortex (Hubel and Wiesel, 1968), without noise ceiling procedures I also got remarkable accuracy in the identification task (about 48.8%, meanwhile the chance level is about 0.8%).</p>
<p>My code is now open sccess on <a href="https://github.com/celelion/Voxels-activity-modeling-using-fMRI-data" target="_blank" rel="external">Github  -  Voxels-activity-modeling-using-fMRI-data</a>.<br><a id="more"></a></p>
<h1 id="About-the-OPEN-ACCESS-data"><a href="#About-the-OPEN-ACCESS-data" class="headerlink" title="About the OPEN ACCESS data"></a>About the OPEN ACCESS data</h1><p>The data comes from <a href="https://crcns.org/data-sets" target="_blank" rel="external">CRCNS - Collaborative Research in Computational </a>.</p>
<p>Data set:</p>
<blockquote>
<p>Kay, K.N.; Naselaris, T.; Gallant, J. (2011): fMRI of human visual areas in response to natural images. CRCNS.org.<br><a href="http://dx.doi.org/10.6080/K0QN64NG" target="_blank" rel="external">http://dx.doi.org/10.6080/K0QN64NG</a></p>
</blockquote>
<h1 id="Stimulus"><a href="#Stimulus" class="headerlink" title="Stimulus"></a>Stimulus</h1><p><div align="center"><img src="http://i1.piimg.com/4851/704e84210b37d372.png" alt="100" width="100"></div></p>
<center>Figure 1. A given example of the natural image stimulus</center>  

<p>Subjects view 1870 images while recording their brain activities using fMRI. 1750 of these are for training, the remaining is the test set.</p>
<p>After the pre-processing procedure. They used GLM to estimate response for every images. Then they choose about 25000 voxels from (V1, V2, V3, V3a, V3b, V4, LatOcc etc.).</p>
<h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><h2 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h2><p><div align="center"><img src="http://i1.piimg.com/4851/98d7f6aff9de2bf3.png" alt="..." width="..."></div></p>
<center>Figure 2. The overview of the data processing procedures. Mainly in three parts, feature extractions, voxels selection, and main training stage.</center> 

<p>In order to modeling voxels’ tunning dynamic. We use this three-stage method. Including feature extractions, voxels selection, and main training(modeling)stage. </p>
<h2 id="Procedures-amp-Results"><a href="#Procedures-amp-Results" class="headerlink" title="Procedures &amp; Results"></a>Procedures &amp; Results</h2><h3 id="Extract-features"><a href="#Extract-features" class="headerlink" title="Extract features"></a>Extract features</h3><p>According the theory of the encoding mechanism of the early visual cortex (EVC). Neurons in EVC firing for some particular orientation and spacial frequency in a particular visual position, which we called the receptive field. In fMRI, the activity patterns in the human visual cortex can also reveal what stimulus orientation a person is viewing(Kamitani &amp; Tong, 2005).</p>
<p>To pick up infomation of orientation and spacial frequency in a natural image. We using the garbor wavelet to project onto every images in different space location, orientation, and spacial frequency, which we called the Gabor wavelet pyramid.</p>
<p>As for the Gabor wavelet pyramid. Wavelets occur at five (or, in some cases, six) spatial frequencies. This panel depicts one wavelet at each of the first five spatial frequencies. At each spatial frequency f cycles per field-of-view (FOV), wavelets are positioned on an f × f grid, as indicated by the translucent lines.Orientation and phase. At each grid position, wavelets occur at eight orientations and two phases. This panel depicts a complete set of wavelets for a single grid position. Dashed lines indicate the bounds of the mask associated with each wavelet.(Kay et al., 2008) Showed below.</p>
<p><div align="center"><img src="http://i1.piimg.com/4851/dc03fc9a075abd7d.png" alt="..." width="..."></div></p>
<center>Figure 3. Gabor wavelet pyramid design.</center> 

<p>There are five different spacial frequency(1,2,4,8,16 FOV). For every single spacial frequency, it has (1,4,16,64,256) types of different position in the visual field. For every position, there are 2 orthogonal phase and 8 different angles(0:22.5:157.5).</p>
<p>Together, there are 5456 different gabor wavelets in the Gabor wavelet pyramid. I used the <strong>gabor_fn.m</strong> function to produce a gabor wavelet for the given sf,angle,phase,posi. <a href="https://en.wikipedia.org/wiki/Gabor_filter" target="_blank" rel="external">from Wikipedia</a></p>
<p>Then, I wrote a function <strong>gaborfit.m</strong> to produce a set of gabor wavelet image directlly. It produce a martix called gab(128x128x5456).Represent 5456 different gabor wavelet image(128x128).</p>
<p>To compute the projection. I wrote compscript.m (section 1). To compute the projection of 5456 wavelets for 1750 images. The projections for each quadrature pair of wavelets are then squared, summed, and square-rooted, yielding a measure of contrast energy. The result will be in the martix called proj(1750x2728).</p>
<p>To remove wavelets ouuside the field of the natural images(outside the circle). I wrote a function called <strong>gabdelete</strong> in gabdelete.m. The result will be in the martix called projdeleteedge(1750x2728).</p>
<h3 id="Training-algorithm"><a href="#Training-algorithm" class="headerlink" title="Training algorithm"></a>Training algorithm</h3><p><div align="center"><img src="http://p1.bpimg.com/4851/2ffdb90439b274fd.png" alt="..." width="..."></div></p>
<center>Figure 4. Gabor wavelet pyramid model..</center> 

<p>Here we use multi-variation liner regression to build up the model. Using the features  which we cauculated before using gabor wavelet pyramid model. </p>
<p>We use the tronditional square-root error cost function, and using gradient descent with monument to optimize the cost function.</p>
<p>$h=h- \varepsilon g$</p>
<p>$g=\left[ \left[ X’(Xh-y) \right]+\alpha g  \right]$</p>
<p>To prevent over-fitting, we used early stopping. A randomly selected 20% of the data-set were removed and kept as a stopping set. Iterations proceeded until the squared error on the stopping set nolonger decreased, or until the squared error on the training set no longer decreased. </p>
<p>I wrote two function to running this regression. inittrain.m and linereg.m</p>
<p>The <strong>initrain.m</strong> is used to pre-processing the dataset, devided it into training set and stopping set for early stopping, and remove NaN data points.</p>
<p>The <strong>linereg.m</strong> is used for running the optimzation of the cost function.</p>
<h3 id="Pre-training-stage"><a href="#Pre-training-stage" class="headerlink" title="Pre-training stage"></a>Pre-training stage</h3><p>Trainning that models for 25000 voxels is too time-consuming. In order to improve efficiency. We carry a pre-training stage.</p>
<p>In order to accelerate the training speed, we tried to reduce dimensions firstly. We did not take orentation into consideration: we averged the 8 gabor wavelet projection for each position.</p>
<p>Then we can use that new features to fit the model. Using the weight for every location we can reconstruct the population receptive field. </p>
<p>This method is pretty likely to build up a data driven pRF(population receptive field).</p>
<p><div align="center"><img src="http://p1.bpimg.com/4851/5bd832ebd9427c9f.png" alt="150" width="300"></div></p>
<center><strong>Figure 5. A given example of the reconstructed pRF.</strong> Left img represent a well-fitted voxel, it’s receptive field is very consentrate and <strong>sparse</strong>. Image in right represent a traditional poorly fitted voxel, it’s receptive field is very confusion.</center> 

<p>I worte _gabor<em>field.m</em> to generate a field map using gaussian functions.<br>The <em>RFvis.m</em> is used for reconstructing a population receptive field map for a given voxels, using the weight computed in the pre-trainning stage and the gabor_field.m, sum it up to form a receptive field map.<br>We need to remove those poorly fitted voxels. We have two ways to select voxels. </p>
<h4 id="1-Gaussian-Fitted"><a href="#1-Gaussian-Fitted" class="headerlink" title="1. Gaussian Fitted"></a>1. Gaussian Fitted</h4><p>We can using Gaussian function to fitted the reconstructed pRF. The Gaussian RMS width(field vaule in fig 5.) can represent the ‘goodness of fit’, but sometimes some poorly-fitted can also be selected because of some overfitting problem.</p>
<h4 id="2-R-Squared-sorting"><a href="#2-R-Squared-sorting" class="headerlink" title="2. R-Squared sorting"></a>2. R-Squared sorting</h4><p>To quantify the ‘goodness of fit’. We can also using R-Squared vaule directly. We cauculate R2 of those 25000 voxels and make a sorting. And we can choose the top 500 voxels to do the futher analyze.</p>
<p>After the R-Squared sorting procedure, the top-10 voxels showed below.</p>
<p><div align="center"><img src="http://p1.bpimg.com/4851/69189a49aa9fd58b.jpg" alt="..." width="..."></div><br> <center><strong>Figure 5. Top 10 well-fitted voxels.</strong> Figure shows the reconstructed pRF of top 10 well-fitted voxels, it’s all has a relatively ‘sparse’ receptive field</center> </p>
<p>The anatomical distribution of those 500 voxels showed below.</p>
<p><div align="center"><img src="http://p1.bqimg.com/4851/2d56f0879a6c869c.jpg" alt="..." width="..."></div><br> <center><strong>Figure 6. The anatomical distribution of those 500 voxels.</strong></center> </p>
<p>As we can see, a huge amount of voxels are from early visual cortex(V1,V2,V3).</p>
<p>I wrote <em>causelectedh.m</em> to select 500 voxels, and further more, to run the main-trainning stage below.</p>
<h3 id="Main-training-stage"><a href="#Main-training-stage" class="headerlink" title="Main-training stage"></a>Main-training stage</h3><p>Have choosen 500 well-fitted voxels. We fitted those voxels with full features(with 8 orientations).<br>I then use this model to predict 500 voxels activities based on 120 natural images in the test set(120 images).<br>Then, We compute R-Squared vaule between actually response value and the predicted vaule of those 500 voxels among those 120 images, using that to generate a 120x120 image.</p>
<p><div align="center"><img src="http://p1.bpimg.com/4851/5ea10a33ac4cf3bc.jpg" alt="..." width="..."></div><br> <center><strong>Figure 6. The correlation map of the actually response value and the predicted vaule of those 500 voxels.</strong> The (i,j)position’s color represent the R-Squared vaule between actually response value of the number i th image and the predicted vaule of the j th image of those 500 voxels.</center> </p>
<p>I wrote <em>corxcmp.m</em> to predict the activity using test set images, and generate this final result.</p>
<p>In the identifation task. We re-match the target’s brain activities with the best correlated predicted brain activities. In my work, without noise ceiling procedures, the identifation performance is about 58.8%, meanwhile, the chance level is about 0.83%.  </p>
<p>Using the optimized wights in the main-training stage. We could generate a tuning properties image. It could tell us which orinentation and spacial frequency contribute more to the activity of the voxels.</p>
<p>As a given example, for the No.23198 voxel, we visualize the weight distribution of the 8 orintations and 5 spacial frequency (5x8).</p>
<p><div align="center"><img src="http://p1.bqimg.com/4851/7c3e2d670fa3c75c.png" alt="200" width="360"></div><br> <center><strong>Figure 7. The weight distribution of the 8 orintation and 5 spacial frequency for the voxel 23198.</strong> .</center> </p>
<p> Further more, we plot the tuning properties for the orintations separately.</p>
<p> <div align="center"><img src="http://p1.bqimg.com/4851/dfeb524e2f63586f.png" alt="200" width="360"></div><br> <center><strong>Figure 8.The tuning properties for the orintations(L) and spacial frequency(R).</strong> .</center> </p>
<p> We can observe that, this voxel prefer 45 degres, and relevantly prefer higher special frequency. Consist with the encoding theory of the early visual cortex.</p>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><p>Gilbert, C. D., &amp; Wiesel, T. N. (1985). Intrinsic connectivity and receptive field properties in visual cortex. Vision research, 25(3), 365-374.</p>
<p>Chen, N., P. Cai, T. Zhou, B. Thompson, and F. Fang. 2016. ‘Perceptual learning modifies the functional specializations of visual cortical areas’, Proc Natl Acad Sci U S A.</p>
<p>Hubel, D. H., and T. N. Wiesel. 1968. ‘Receptive fields and functional architecture of monkey striate cortex’, Journal of Physiology, 195: 215-43.</p>
<p>Huth, A. G., W. A. de Heer, T. L. Griffiths, F. E. Theunissen, and J. L. Gallant. 2016. ‘Natural speech reveals the semantic maps that tile human cerebral cortex’, Nature, 532: 453-8.</p>
<p>Kandel, E., and J. Schwartz. 2013. Principles of Neural Science, Fifth Edition (McGraw-Hill Education).</p>
<p>Kay, K. N., T. Naselaris, R. J. Prenger, and J. L. Gallant. 2008. ‘Identifying natural images from human brain activity’, Nature, 452: 352-5.</p>
<p>Miyawaki, Y., H. Uchida, O. Yamashita, M. A. Sato, Y. Morito, H. C. Tanabe, N. Sadato, and Y. Kamitani. 2008. ‘Visual image reconstruction from human brain activity using a combination of multiscale local image decoders’, Neuron, 60: 915-29.</p>
<p>Naselaris, T., K. N. Kay, S. Nishimoto, and J. L. Gallant. 2011. ‘Encoding and decoding in fMRI’, NeuroImage, 56: 400-10.</p>
<p>Norman, K. A., S. M. Polyn, G. J. Detre, and J. V. Haxby. 2006. ‘Beyond mind-reading: multi-voxel pattern analysis of fMRI data’, Trends Cogn Sci, 10: 424-30.</p>
<p>Sprague, T. C., &amp; Serences, J. T. (2013). Attention modulates spatial priority maps in the human occipital, parietal and frontal cortices. Nat Neurosci, 16(12), 1879-1887. doi:10.1038/nn.3574</p>

      
    </div>
    
  </div>
  
    


    <nav id="article-nav">
        
            <div id="article-nav-newer" class="article-nav-title">
                <a href="/2016/08/22/A_summer_in_PKU/">
                    A summer in PKU, A summer in Fang&#39;s lab
                </a>
            </div>
        
        
            <div id="article-nav-older" class="article-nav-title">
                <a href="/2016/03/10/visual_image_reconstruction/">
                    Visual Image Reconstruction using fMRI
                </a>
            </div>
        
    </nav>

  
</article>

    <div id="toc" class="toc-article">
        <strong class="toc-title">Contents</strong>
        
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#About-the-OPEN-ACCESS-data"><span class="toc-number">1.</span> <span class="toc-text">About the OPEN ACCESS data</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Stimulus"><span class="toc-number">2.</span> <span class="toc-text">Stimulus</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Method"><span class="toc-number">3.</span> <span class="toc-text">Method</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Overview"><span class="toc-number">3.1.</span> <span class="toc-text">Overview</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Procedures-amp-Results"><span class="toc-number">3.2.</span> <span class="toc-text">Procedures & Results</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Extract-features"><span class="toc-number">3.2.1.</span> <span class="toc-text">Extract features</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Training-algorithm"><span class="toc-number">3.2.2.</span> <span class="toc-text">Training algorithm</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Pre-training-stage"><span class="toc-number">3.2.3.</span> <span class="toc-text">Pre-training stage</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#1-Gaussian-Fitted"><span class="toc-number">3.2.3.1.</span> <span class="toc-text">1. Gaussian Fitted</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#2-R-Squared-sorting"><span class="toc-number">3.2.3.2.</span> <span class="toc-text">2. R-Squared sorting</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Main-training-stage"><span class="toc-number">3.2.4.</span> <span class="toc-text">Main-training stage</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#References"><span class="toc-number">4.</span> <span class="toc-text">References</span></a></li></ol>
        
    </div>
    <style>
        .left-col .switch-btn,
        .left-col .switch-area {
            display: none;
        }
        .toc-level-3 i,
        .toc-level-3 ol {
            display: none !important;
        }
    </style>

    <input type="button" id="tocButton" value="Hide"  title="Show or Hide Table of Contents">

    <script>
        yiliaConfig.toc = ["Hide", "Show", !!"false"];
    </script>



    
<div class="share">
    
        <div class="bdsharebuttonbox">
            <a href="#" class="fa fa-twitter bds_twi" data-cmd="twi" title="分享到推特"></a>
            <a href="#" class="fa fa-weibo bds_tsina" data-cmd="tsina" title="分享到新浪微博"></a>
            <a href="#" class="fa fa-qq bds_sqq" data-cmd="sqq" title="分享给 QQ 好友"></a>
            <a href="#" class="fa fa-files-o bds_copy" data-cmd="copy" title="复制网址"></a>
            <a href="#" class="fa fa fa-envelope-o bds_mail" data-cmd="mail" title="通过邮件分享"></a>
            <a href="#" class="fa fa-weixin bds_weixin" data-cmd="weixin" title="生成文章二维码"></a>
            <a href="#" class="fa fa-share-alt bds_more" data-cmd="more"></i></a>
        </div>
        <script>
            window._bd_share_config={
                "common":{"bdSnsKey":{},"bdText":"Nature image identification and voxels activity modeling using fMRI encoding model　| JingjieLi’s Brain　","bdMini":"2","bdMiniList":false,"bdPic":"","bdStyle":"0","bdSize":"24"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];
        </script>
    

    
</div>







    




    <div class="scroll" id="post-nav-button">
        
            <a href="/2016/08/22/A_summer_in_PKU/" title="Pre: A summer in PKU, A summer in Fang&#39;s lab">
                <i class="fa fa-angle-left"></i>
            </a>
        

        <a title="Mini Archives"><i class="fa fa-bars"></i><i class="fa fa-times"></i></a>

        
            <a href="/2016/03/10/visual_image_reconstruction/" title="Next: Visual Image Reconstruction using fMRI">
                <i class="fa fa-angle-right"></i>
            </a>
        
    </div>

    <ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2017/02/10/vssabsacc/">My abstract was accepted by VSS 2017</a></li><li class="post-list-item"><a class="post-list-link" href="/2017/01/25/aboutme/">Something About Jingjie</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/08/22/A_summer_in_PKU/">A summer in PKU, A summer in Fang's lab</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/06/14/nature-image-identification/">Nature image identification and voxels activity modeling using fMRI encoding model</a></li><li class="post-list-item"><a class="post-list-link" href="/2016/03/10/visual_image_reconstruction/">Visual Image Reconstruction using fMRI</a></li></ul>




    <script>
        
    </script>
</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                <i class="fa fa-copyright"></i> 
                2016-2017 Jingjie Li
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank" title="A fast, simple &amp; powerful blog framework">Hexo</a>  Theme <a href="https://github.com/MOxFIVE/hexo-theme-yelee" target="_blank" title="Another simple and elegant theme for Hexo  v3.5">Yelee</a> by MOxFIVE <i class="fa fa-heart animated infinite pulse"></i>
            </div>
        </div>
        
    </div>
</footer>
    </div>
    
<script data-main="/js/main.js" src="//cdn.bootcss.com/require.js/2.2.0/require.min.js"></script>





    <script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.bootcss.com/mathjax/2.6.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


<div class="scroll" id="scroll">
    <a href="#" title="Back to Top"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments" onclick="load$hide();" title="Comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer" title="Go to Bottom"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    // Open in New Window
    
        var oOpenInNew = {
            
            
            
            
            
            
             archives: ".archive-article-title", 
             miniArchives: "a.post-list-link", 
            
             friends: "#js-friends a", 
             socail: ".social a" 
        }
        for (var x in oOpenInNew) {
            $(oOpenInNew[x]).attr("target", "_blank");
        }
    
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
  </div>
</body>
</html>
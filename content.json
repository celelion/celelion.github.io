{"meta":{"title":"JingjieLi’s Brain","subtitle":"A junior from Xi’an Jiaotong University(XJTU)","description":"My Personal Blog","author":"Jingjie Li","url":"http://www.jingjie.site"},"pages":[{"title":"Timeline","date":"2017-09-22T16:42:40.000Z","updated":"2017-09-22T16:42:40.000Z","comments":true,"path":"timeline/index.html","permalink":"http://www.jingjie.site/timeline/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"Tags & Catagories","date":"2017-09-22T16:41:45.000Z","updated":"2017-09-22T16:41:45.000Z","comments":true,"path":"tags/index.html","permalink":"http://www.jingjie.site/tags/index.html","excerpt":"","text":"","raw":null,"content":null},{"title":"Something About Jingjie","date":"2017-11-03T17:19:55.000Z","updated":"2017-12-08T15:26:55.000Z","comments":true,"path":"about/index.html","permalink":"http://www.jingjie.site/about/index.html","excerpt":"","text":"EducationI’m Jingjie Li, a sophomore from Xi’an Jiaotong University(XJTU), Majoring in BME(BioMedical Engineering). In July, 2016. I attended the 4th CLS/McG neuroscience summer school in Peking University. From Jun. 2017 to Sep. 2017. I attended the 1th Summer Undergraduate Research Program(SURP) at New York University Shanghai You can download my CV here. Research InterestI’m interested in neuroscience. I would like to seek for how our brain interpret the sensory signal, particularly the visual perception. Topics including attentional modulation, the expectation effect and the predictive coding in sensory processing. At present, I’m trying to interpret why intermittent presented SFM can stablization subject’s perception. Using combination of psychphysical experiments and functional imagining. I also have a project about visual working memory in the rodent. Currently we are trainning the mice and rats to do that task. Lab Experience2016 03 - NOWUndergraduate Researcher, Institute of Artificial Intelligence and Robotics, Xi’an Jiaotong University Advisor: Prof. Badong Chen Project 1 : Visual image reconstruction using fMRI(In March, 2016) This work is about repeating a pioneering research, decode fMRI signal from primary visual cortex (V1) and reconstruct pattern image from fMRI signal (Miyawaki et al., 2008), meanwhile, I improved the accuracy of the reconstruction by about 4% (from about 80% to about 84%), using the improved MVPA method with SVM classifier (Norman et al., 2006). For more detail: Click HERE Project 2 : Modeling fMRI voxels dynamics with natural image stimulus(In May, 2016) This work is about repeating a pioneering research(Kay et al., 2008), modeling voxels activities in visual cortex using the Voxel-Wise Model (Naselaris et al., 2011), I successfully constructed a liner receptive field model for every voxels using the Gabor wavelet filter according to the encoding theory of the primary visual cortex (Hubel and Wiesel, 1968), without noise ceiling procedures I also got remarkable accuracy in the identification task (about 48.8%, meanwhile the chance level is about 0.8%). For more detail: Click HERE Project 3 : How visual working memory effects visual perception(Sep. 2016 - NOW) In this project, I am trying to carry out my own independent research projrct for the first time. I am using a combination of psychophysics experiments, and functional imaging(fMRI, EEG). My results indicated that the working memory task could improve the perceptual memory performance via enhancing the internally representation, and we can impair the perceptual memory by distribute this internally representation(Dec. 2016). I presented my result in VSS 2017. For more detail: Click HERE 2017 07 - 2017 09Undergraduate Researcher, NYU-ECNU Institute of Brain and Cognitive Science, New York University ShanghaiAdvisor: Prof. Jeffrey C. Erlich Project 1 : Visual working memory based decision making task for the Rodent(Jun. 2017 - NOW) In this project, I Learned to program the state-of-the-art B-Pod behavioral training system developed by the lab, and designed a 9-stage experiment protocol to train mice to perform a visual working-memory guided orienting task. In this task, the mouse needs to interact with the B-Pod system: using the light color as a cue ,then after a short delay, it will choose the port that matched the cue to gain reward. After the project, I Received highly evaluation from Dr. Erlich. My work is reported at NYU’s website. For more detail: Click HERE Project 2 : History dependance modeling (time-normalization divisive model) of the experiential based delay-reward decision-making tasks for human subjects (Aug. 2017) In this project, I developed few computational models for measuring and detecting history dependence in experiential based delay-reward decision-making tasks. I Found that bigger the delay the more history matters, however, the parameter responsible for the history is negligibly small. The model fails to beat the simple hyperbolic model in terms of BIC(Bayesian information criterion) on the same dataset. 2016 07 - 2016 08Visitor, School of Psychlogical and Cognitive Science, Peking University Advisor: Prof. Fang Fang Spent 5 weeks in Fang Fang’s lab in PKU. I learnt 1)How to actually running my own psychophysics experiments with psychtoolbox, 2)How to actually running fMRI experiments, and how to dealing with the fMRI raw data using SPM12, 3)Most importantly, how a graduate student in cognitive neuroscience reasoning.For more detail: Click HERE 2016 11 - NOWUndergraduate Researcher, Department of BioMedical Engineering, Xi’an Jiaotong UniversityAdvisor: Prof. Gang Wang Project 1 : Anesthesia monitoring using combination of Bispectral, WT, FFT and entropy analyze in EEG signal. In this project, I studied how to using algorithms like 1) WT, FFT analyze to capture the time-frequency characteristics, 2) using Bispectral to detect phase coupling characteristics, and 3) using entropy\\ complexity analyze to capture the none-linearity characteristics of EEG signal. Skills Psychophysical : Psychtoolbox programming(MATLAB) &amp; basic experiment design skills fMRI data analyze : SPM12 Preprocessing and Univariate analyze, MVPA, forward encoding model, voxels activities modeling (Voxel-Wise Model) EEG data analyze : Running EEG experiments with neuroscan devices, ERP analyze using scan 4.5 &amp; Curry 7 Rodent Experiment : Developing and running rodent experiment protocol using B- Pod System (Open source rodent behavior measurement and control). C &amp; C++, Python, Matlab, Verilog HDL(FPGA), Assembly language, Git, SQL DB Publications2017 Jingjie Li, Hao Wu, Badong Chen. Visual working memory affects the perception of ambiguous SFM (structure-from-motion) by enhancing internal representation, Poster presented at the 17th Annual Meeting of the Vision Sciences Society. Naples, FL. Courses (Only listed online courses)As cognitive neuroscience a interdisciplinary subject, carrying out research in this field need some other skills and knowledge in math and programming etc. In order to strengthen my programming skills and to gain some knowledge of other interdisciplinary subjects(Data Science, Meachine Learning). I participated in several online courses(MOOCs), mainly in Coursea.org. For detiles CLICK HERE Introduction to Programming with MATLAB Meachine Learning Principles of fMRI 1 Neural Networks for Machine Learning Books I’ve read Kandel, E., &amp; Schwartz, J. (2013). Principles of Neural Science, Fifth Edition: McGraw-Hill Education. Dayan, P., &amp; Abbott, L. F. (2001). Theoretical neuroscience (Vol. 10): Cambridge, MA: MIT Press. Marr, D. (1982). Vision: A computational approach: Freeman. Honors2016 Siyuan Scholarship in Xi’an Jiaotong University(40%) Outstanding Student in Xi’an Jiaotong University(20%) 2017 Siyuan Scholarship in Xi’an Jiaotong University(40%) Outstanding Student in Xi’an Jiaotong University(20%) Contact MeMy Email: jingjie.li@nyu.edu jingjie.li@stu.xjtu.edu.cn lijingjiepoi@gmail.com My Wechat id: lijingjiepoi","raw":null,"content":null}],"posts":[{"title":"My own B-Pod System using FPGA and MATLAB","slug":"My-own-B-Pod-System-using-FPGA-and-MATLAB","date":"2017-12-08T13:59:09.000Z","updated":"2017-12-08T15:24:23.000Z","comments":true,"path":"2017/12/08/My-own-B-Pod-System-using-FPGA-and-MATLAB/","link":"","permalink":"http://www.jingjie.site/2017/12/08/My-own-B-Pod-System-using-FPGA-and-MATLAB/","excerpt":"Working with rodents in NYU Shanghai last summer, I found that rodent decision-making is so amazing. So, In the electronic design class in this semester, I tried to make a B-Pod system using FPGA and MATLAB by my own. So I can use that to carry out my own rodent experiment in the future.","text":"Working with rodents in NYU Shanghai last summer, I found that rodent decision-making is so amazing. So, In the electronic design class in this semester, I tried to make a B-Pod system using FPGA and MATLAB by my own. So I can use that to carry out my own rodent experiment in the future. I open-accessed all my code on Github, here is the LINK. About the BPODThe B-Pod system is developed by Joshua Sanders in his initial open research instruments (The BPOD r0.5) while completing his PhD in Kepecs Lab at Cold Spring Harbor Laboratory. Bacis idea of the BPOD systemThe basic idea of the bpod is to interact with the rodent using light or sound cue, and give them reward when they perform will. So the core problem is to detect rodents’ activity. Fig 1. We have several LEDs around the ports and the sound in the mouse box to ‘tell’ the animal ‘what to do’ To do so, we are using an IR emitter paired with an IR collector for each port. So everytime when the animal ‘poke’ into the port. The light from IR emitter will be block, so we can detect voltage change from the IR collector. Fig 2. We are using IR to detect animals’ behaviour Using FPGA to control and monitering the devices.In my project, I’m using a FPGA(Field-Programmable Gate Array) to control the LEDs and water value in the three mouse ports. Meanwhile, The FPGA is also used for monitering the IR collector of the three ports. Fig 3. The connection diagram of the firmware The FPGA is connected to the MAC computer via a serial-USB convert line. And the MATLAB is able to talk with the FPGA via this serial port. Once the IR system detect the mouse’s activity, the IR collector will sent signals to the FPGA. Then the FPGA will send an 8-bits information contains that information. The FPGA keeps contraling the LEDs and water pump. When the MATLAB want to change a state(For example, turn on/off the light, open the water). It will sent a 8-bits information via serial port to re-write the state vector in FPGA. FPGA then change the target voltage in it’s ports. Because the voltage of the IR system is 5V and the voltage of the FPGA is 3.3v, I passed the IR output to a voltage convertor and a 74HC14 to reverse the voltage. The it will be sent to the FPGA, 3.3v means a ‘block’ is there, and 0v means this port is clear. Fig 4. The connection diagram of the FPGA Connected all these firmware things. The FPGA, the LEDs, the IR ports, the 74HC14 chips and the computer, It looks like this. But it works pretty well. Fig 5. The testing firmware Using MATLAB to control the FPGA using FSMIn the computer, the MATLAB will generate a FSM(Finate State Meachine) based on the design of the experiment protocol to control the FPGA. The animals’ behavioul will trigger the stage switching. We define a class to describe the experiment protocol. The simplist version is called the ‘Operant’, in ‘Protocols/Operant’ path. It contains several sub-functions. init Section: Initialze the protocol, creating Sounds etc. useSetting Section: do some basic settings to the session. and load some old settings from previous experiment. PreparNextTrial Section: set the paramenters of the next trial based on prob. or history performance. RunTrial Section: Generate the FSM and run the trial. TrialComplete Section: do dome basic computation and analyze to this trial’s data. saveTrial section: save this trials data to the table. The dispatch.m in the modules path will call different parts of that class again and again. It also have many try-catch sentences, so that it will isolate bugs within each section and not affect running of the experiment. Also, I designed a subject management system there. We we input the subject’s id when starting the experiment, the program will record the stage and the information. So everthing will go automatically. The Basic Trainning ProtocolMy system contains a basic Protocol named ‘Operant’. It’s a very general protocol that can be used to train animals to associate lights or sounds with reward. To train the animals, we need to follow up a stage-to-stage procedure. The basic idea is shown below. In ‘Operant’, we have three stages. Fig 6. State diagram of the stage 1 First stage: ‘reward_train’. We will give them unconditional reward, just let them learn to drink. When they learnt how to drink, we will jump to the stage 2. Fig 7. State diagram of the stage 2Secound stage: ‘single_poke’. In this stage, we will turn the light of a port randomly, and wait for the animal to poke into that port. If they do well, they will get water reward, otherwise, they will hear about a short violation sound and no reward. When they got &gt;75% performance in the past 30 trials, they will go to the stage 3. The Next StepCurrerently, I’m working on the water pump and the rig-box. After that, I’ll try to train several mouse and rats.","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"News","slug":"News","permalink":"http://www.jingjie.site/tags/News/"},{"name":"XJTU","slug":"XJTU","permalink":"http://www.jingjie.site/tags/XJTU/"},{"name":"Hardware","slug":"Hardware","permalink":"http://www.jingjie.site/tags/Hardware/"}]},{"title":"SURP in NYU Shanghai","slug":"SURP in NYU Shanghai","date":"2017-11-04T10:05:54.000Z","updated":"2017-12-08T14:02:25.000Z","comments":true,"path":"2017/11/04/SURP in NYU Shanghai/","link":"","permalink":"http://www.jingjie.site/2017/11/04/SURP in NYU Shanghai/","excerpt":"In the summer, I joined the SURP (Summer Undergraduate Research Program). Ran a 10-week research experience in NYU-ECNU institute for brain and cognitive sciences at NYU(New York University) Shanghai.","text":"In the summer, I joined the SURP (Summer Undergraduate Research Program). Ran a 10-week research experience in NYU-ECNU institute for brain and cognitive sciences at NYU(New York University) Shanghai. NYU’s News about me and the SURP:Nurturing Science Careers: NYU Shanghai’s Incubator for Future Neuroscientists Because my previous research in Visual Working memory, I was paired up with Dr. Jeffrey Erlich, Assistant Professor of Neural and Cognitive Sciences at NYU Shanghai for their shared interest in working memory. In this summer, I mainly focused on my own visual-working memory project. I stuided visual working memory(VWM) based decision making in the rodent. I quickly learned to program the state-of-the-art B-Pod behavioral training system developed by the lab, and I designed a 9-stage experiment protocol to train mice to perform a visual working-memory task. Mouse was performing the visual working memory task In the end, my advisor (Dr. Jeffrey Erlich) highly appraised my work. he said: I was really impressed by Jingjie’s dedication and skills. He made a real contribution during his summer in the lab’. (Shown in the NYU Shanghai Website) I was speaking at the SURP final presentation With Dr. Jeffrey C. Erlich in the lab In this project. I read several articles first to reasoning the hypothesis and then developed a protocol to train animals. In this entire project, I learn much about how to exactly running experiments on rodent using BPOD system, and how to work collaboratively using Git.","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"News","slug":"News","permalink":"http://www.jingjie.site/tags/News/"},{"name":"Summer Research","slug":"Summer-Research","permalink":"http://www.jingjie.site/tags/Summer-Research/"},{"name":"NYU","slug":"NYU","permalink":"http://www.jingjie.site/tags/NYU/"}]},{"title":"Present My Work in VSS 2017","slug":"gotovss","date":"2017-05-30T09:20:14.000Z","updated":"2017-09-23T12:31:45.000Z","comments":true,"path":"2017/05/30/gotovss/","link":"","permalink":"http://www.jingjie.site/2017/05/30/gotovss/","excerpt":"Few days ago, I attended VSS 2017 conference in St. Pete Beach. And presented my work in poster.","text":"Few days ago, I attended VSS 2017 conference in St. Pete Beach. And presented my work in poster. Here is my poster presentation. And a online-version of my Poster. If you are interested about my work. Please contact me directly via jingjie.li@nyu.edu or jingjie.li@stu.xjtu.edu.cn","raw":null,"content":null,"categories":[{"name":"Publications","slug":"Publications","permalink":"http://www.jingjie.site/categories/Publications/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"News","slug":"News","permalink":"http://www.jingjie.site/tags/News/"},{"name":"Publications","slug":"Publications","permalink":"http://www.jingjie.site/tags/Publications/"},{"name":"VSS","slug":"VSS","permalink":"http://www.jingjie.site/tags/VSS/"}]},{"title":"Courses I've taken (MOOC)","slug":"courses","date":"2017-02-15T07:52:25.000Z","updated":"2017-09-22T17:25:48.000Z","comments":true,"path":"2017/02/15/courses/","link":"","permalink":"http://www.jingjie.site/2017/02/15/courses/","excerpt":"As cognitive neuroscience a interdisciplinary subject, carrying out research in this field need some other skills and knowledge in math and programming etc.\nIn order to strengthen my programming skills and to gain some knowledge of other interdisciplinary subjects(Data Science, Meachine Learning). I participated in several online courses(MOOCs), mainly in Coursea.org.","text":"As cognitive neuroscience a interdisciplinary subject, carrying out research in this field need some other skills and knowledge in math and programming etc. In order to strengthen my programming skills and to gain some knowledge of other interdisciplinary subjects(Data Science, Meachine Learning). I participated in several online courses(MOOCs), mainly in Coursea.org. Moocs I’ve TakenCourses List(The courses I’ve taken in school showed in my Transcript). MOOCs are listed below. Introduction to Programming with MATLAB Meachine Learning Principles of fMRI 1 Neural Networks for Machine Learning Introduction to Programming with MATLAB — 07 2015-09 2015After graduate from high school, I participated in this course in the up-coming summer vocation. In order to improve my programming skills with MATLAB. This course benefit me a lot for further study and research. Certification Meachine Learning (By Andrew Ng) — 09 2015-11 2015Further, I participated in this course in the first semester of freshman. In this course, I got basic understanding about what meachine learning algorithms do. I studied several algorithms, including Liner Regression, Logestic Regression, Feed Forward Neural Network, SVM, PCA, K-means, Collaborative filtering etc. After this course, I can use MATLAB to running simple meachine learning algorithms. That lay foundation for my further study using MVPA and Encoding Models. Certification Principles of fMRI 1 — 09 2015-11 2015In spring 2016 semester, I participated in this course for gaining basic understanding of fMRI. In this course, I studied some basic knowledge of fMRI and fMRI data analyze. Mainly about several points: 1)fMRI Data Structure, 2)Basic MR Physics and imaging, 3)Signal, Noise, and BOLD Physiology,4)fMRI Experiment Design,5)Pre-Processing of fMRI Data,6)GLM univariate analyze and t-contrast Also, We tried to make a note od this course for Chinese learner. It’s now open access in Zhihu, has gathered for about 200 up-votes. Neural Networks for Machine Learning — 10 2016-02 2017In fall 2016 semester, I participated in this course for gaining more understanding about meachine learning, particularly about (deep) neural networks. I learnt about Perceptron, Feed Forward Neural Networ, RBM, Deep Belief Nets, and auto encoders etc. Most importently, I known how to trainning a deep neural network using unsuperviced learning with pre-trainning processing. I also realized that the learning rule of RBM and DBN also share some same point with LTDP in neural system. This course provide me with not only skills and knowledge about neual network ,also inspire me to do futher thinking about meachine learning and neuroscience. Certification","raw":null,"content":null,"categories":[{"name":"Study Experience","slug":"Study-Experience","permalink":"http://www.jingjie.site/categories/Study-Experience/"}],"tags":[{"name":"Me","slug":"Me","permalink":"http://www.jingjie.site/tags/Me/"},{"name":"Courses","slug":"Courses","permalink":"http://www.jingjie.site/tags/Courses/"},{"name":"MOOCs","slug":"MOOCs","permalink":"http://www.jingjie.site/tags/MOOCs/"}]},{"title":"A summer in PKU, A summer in Fang's lab","slug":"A_summer_in_PKU","date":"2016-08-22T05:31:28.000Z","updated":"2017-09-23T12:25:47.000Z","comments":true,"path":"2016/08/22/A_summer_in_PKU/","link":"","permalink":"http://www.jingjie.site/2016/08/22/A_summer_in_PKU/","excerpt":"In the summer vocation, 2016. I spent a whole summer in Peking University. Attending the neuroscience summer school. After the summer school, I emailed Prof Fang Fang to require a chance to study more. He gave me a positive repley, I then stayed in prof. Fang Fang’s lab as a research intern for 5 weeks.\n6 Weeks in PKU is very meaninful. The lectures in the summer school expand my horizeon greatly. 5 weeks in Fang’s lab tought my how a graduate student in cognitive neuroscience reasoning and working.","text":"In the summer vocation, 2016. I spent a whole summer in Peking University. Attending the neuroscience summer school. After the summer school, I emailed Prof Fang Fang to require a chance to study more. He gave me a positive repley, I then stayed in prof. Fang Fang’s lab as a research intern for 5 weeks. 6 Weeks in PKU is very meaninful. The lectures in the summer school expand my horizeon greatly. 5 weeks in Fang’s lab tought my how a graduate student in cognitive neuroscience reasoning and working. In Fang’s lab. I learnt these three skills below. Running my own psychophysical experimentsIn Fang’s lab. I learnt to programing with PTB(Psychtoolbox) using MATLAB. I carried out a pre-experiment to see how a prior unambigious SFM(Structure from motion) effects the up-coming bistable SFM. Figure 1. Carrying my own psychophysics experiments The psychophysical protocol show below. Figure 2. The psychophysical protocol of my pre-experiment Then I fitted a psychophysical curve to actually ‘see’ this influence. Dealing with fMRI raw dataThey gave me a fMRI data set used for trainning. Using that, I studied how to use SPM to manipulate these data. Including Preprocessing(Slice-timing correction, Motion Correction, Co-registration, Spacial Normalization, and Spatial Smoothing.), and uni-variation GLM analyze. Figure showed below. Figure 3. Manipulate fMRI raw data using SPM 12 Also, using SPM plug-in tools like XjView and MarsBar, I carried out an ROI analyze. I ploted the BSC in MT+, showed below. Figure 4. Bold signal change percentage in MT+ Reasoning and thinking like a graduate studentSpent 5 weeks in Fang’s lab benifit me a lot. I got familiar with the graduate students in fang’s lab, understood what they do and how they think, reading more research articles based on their recommendation, and discussing about my own experiment. The experience in there promote me to think, to try and to act more. It refresh my plan about what to do in the future. Without this experience, I cannot carry my own research project in the past semester. Thank you professor fang fang, and all lab members in fang’s lab.","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"},{"name":"Study Experience","slug":"Research-Experience/Study-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/Study-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"PKU","slug":"PKU","permalink":"http://www.jingjie.site/tags/PKU/"},{"name":"fMRI","slug":"fMRI","permalink":"http://www.jingjie.site/tags/fMRI/"},{"name":"Psychophysics","slug":"Psychophysics","permalink":"http://www.jingjie.site/tags/Psychophysics/"},{"name":"Summer School","slug":"Summer-School","permalink":"http://www.jingjie.site/tags/Summer-School/"}]},{"title":"Nature image identification and voxels activity modeling using fMRI encoding model","slug":"nature-image-identification","date":"2016-06-14T07:47:18.000Z","updated":"2017-09-23T12:26:06.000Z","comments":true,"path":"2016/06/14/nature-image-identification/","link":"","permalink":"http://www.jingjie.site/2016/06/14/nature-image-identification/","excerpt":"In may,2016. I tried to repeat a pioneering research published on NATURE (Kay et al., 2008), using a data-driven Voxel-Wise Model (Naselaris et al., 2011), I successfully constructed a liner receptive field model for every voxels using the Gabor wavelet filter according to the encoding theory of the primary visual cortex (Hubel and Wiesel, 1968), without noise ceiling procedures I also got remarkable accuracy in the identification task (about 48.8%, meanwhile the chance level is about 0.8%).\nMy code is now open sccess on Github  -  Voxels-activity-modeling-using-fMRI-data.","text":"In may,2016. I tried to repeat a pioneering research published on NATURE (Kay et al., 2008), using a data-driven Voxel-Wise Model (Naselaris et al., 2011), I successfully constructed a liner receptive field model for every voxels using the Gabor wavelet filter according to the encoding theory of the primary visual cortex (Hubel and Wiesel, 1968), without noise ceiling procedures I also got remarkable accuracy in the identification task (about 48.8%, meanwhile the chance level is about 0.8%). My code is now open sccess on Github - Voxels-activity-modeling-using-fMRI-data. About the OPEN ACCESS dataThe data comes from CRCNS - Collaborative Research in Computational . Data set: Kay, K.N.; Naselaris, T.; Gallant, J. (2011): fMRI of human visual areas in response to natural images. CRCNS.org.http://dx.doi.org/10.6080/K0QN64NG Stimulus Figure 1. A given example of the natural image stimulus Subjects view 1870 images while recording their brain activities using fMRI. 1750 of these are for training, the remaining is the test set. After the pre-processing procedure. They used GLM to estimate response for every images. Then they choose about 25000 voxels from (V1, V2, V3, V3a, V3b, V4, LatOcc etc.). MethodOverview Figure 2. The overview of the data processing procedures. Mainly in three parts, feature extractions, voxels selection, and main training stage. In order to modeling voxels’ tunning dynamic. We use this three-stage method. Including feature extractions, voxels selection, and main training(modeling)stage. Procedures &amp; ResultsExtract featuresAccording the theory of the encoding mechanism of the early visual cortex (EVC). Neurons in EVC firing for some particular orientation and spatial frequency in a particular visual position, which we called the receptive field. In fMRI, the activity patterns in the human visual cortex can also reveal what stimulus orientation a person is viewing(Kamitani &amp; Tong, 2005). To pick up infomation of orientation and spatial frequency in a natural image. We using the garbor wavelet to project onto every images in different space location, orientation, and spatial frequency, which we called the Gabor wavelet pyramid. As for the Gabor wavelet pyramid. Wavelets occur at five (or, in some cases, six) spatial frequencies. This panel depicts one wavelet at each of the first five spatial frequencies. At each spatial frequency f cycles per field-of-view (FOV), wavelets are positioned on an f × f grid, as indicated by the translucent lines.Orientation and phase. At each grid position, wavelets occur at eight orientations and two phases. This panel depicts a complete set of wavelets for a single grid position. Dashed lines indicate the bounds of the mask associated with each wavelet.(Kay et al., 2008) Showed below. Figure 3. Gabor wavelet pyramid design. There are five different spatial frequency(1,2,4,8,16 FOV). For every single spatial frequency, it has (1,4,16,64,256) types of different position in the visual field. For every position, there are 2 orthogonal phase and 8 different angles(0:22.5:157.5). Together, there are 5456 different gabor wavelets in the Gabor wavelet pyramid. I used the gabor_fn.m function to produce a gabor wavelet for the given sf,angle,phase,posi. from Wikipedia Then, I wrote a function gaborfit.m to produce a set of gabor wavelet image directlly. It produce a martix called gab(128x128x5456).Represent 5456 different gabor wavelet image(128x128). To compute the projection. I wrote compscript.m (section 1). To compute the projection of 5456 wavelets for 1750 images. The projections for each quadrature pair of wavelets are then squared, summed, and square-rooted, yielding a measure of contrast energy. The result will be in the martix called proj(1750x2728). To remove wavelets ouuside the field of the natural images(outside the circle). I wrote a function called gabdelete in gabdelete.m. The result will be in the martix called projdeleteedge(1750x2728). Training algorithm Figure 4. Gabor wavelet pyramid model.. Here we use multi-variation liner regression to build up the model. Using the features which we cauculated before using gabor wavelet pyramid model. We use the tronditional square-root error cost function, and using gradient descent with monument to optimize the cost function. $h=h- \\varepsilon g$ $g=\\left[ \\left[ X’(Xh-y) \\right]+\\alpha g \\right]$ To prevent over-fitting, we used early stopping. A randomly selected 20% of the data-set were removed and kept as a stopping set. Iterations proceeded until the squared error on the stopping set nolonger decreased, or until the squared error on the training set no longer decreased. I wrote two function to running this regression. inittrain.m and linereg.m The initrain.m is used to pre-processing the dataset, devided it into training set and stopping set for early stopping, and remove NaN data points. The linereg.m is used for running the optimzation of the cost function. Pre-training stageTrainning that models for 25000 voxels is too time-consuming. In order to improve efficiency. We carry a pre-training stage. In order to accelerate the training speed, we tried to reduce dimensions firstly. We did not take orentation into consideration: we averged the 8 gabor wavelet projection for each position. Then we can use that new features to fit the model. Using the weight for every location we can reconstruct the population receptive field. This method is pretty likely to build up a data driven pRF(population receptive field). Figure 5. A given example of the reconstructed pRF. Left img represent a well-fitted voxel, it’s receptive field is very consentrate and sparse. Image in right represent a traditional poorly fitted voxel, it’s receptive field is very confusion. I worte _gaborfield.m to generate a field map using gaussian functions.The RFvis.m is used for reconstructing a population receptive field map for a given voxels, using the weight computed in the pre-trainning stage and the gabor_field.m, sum it up to form a receptive field map.We need to remove those poorly fitted voxels. We have two ways to select voxels. 1. Gaussian FittedWe can using Gaussian function to fitted the reconstructed pRF. The Gaussian RMS width(field vaule in fig 5.) can represent the ‘goodness of fit’, but sometimes some poorly-fitted can also be selected because of some overfitting problem. 2. R-Squared sortingTo quantify the ‘goodness of fit’. We can also using R-Squared vaule directly. We cauculate R2 of those 25000 voxels and make a sorting. And we can choose the top 500 voxels to do the futher analyze. After the R-Squared sorting procedure, the top-10 voxels showed below. Figure 5. Top 10 well-fitted voxels. Figure shows the reconstructed pRF of top 10 well-fitted voxels, it’s all has a relatively ‘sparse’ receptive field The anatomical distribution of those 500 voxels showed below. Figure 6. The anatomical distribution of those 500 voxels. As we can see, a huge amount of voxels are from early visual cortex(V1,V2,V3). I wrote causelectedh.m to select 500 voxels, and further more, to run the main-trainning stage below. Main-training stageHave choosen 500 well-fitted voxels. We fitted those voxels with full features(with 8 orientations).I then use this model to predict 500 voxels activities based on 120 natural images in the test set(120 images).Then, We compute R-Squared vaule between actually response value and the predicted vaule of those 500 voxels among those 120 images, using that to generate a 120x120 image. Figure 6. The correlation map of the actually response value and the predicted vaule of those 500 voxels. The (i,j)position’s color represent the R-Squared vaule between actually response value of the number i th image and the predicted vaule of the j th image of those 500 voxels. I wrote corxcmp.m to predict the activity using test set images, and generate this final result. In the identifation task. We re-match the target’s brain activities with the best correlated predicted brain activities. In my work, without noise ceiling procedures, the identifation performance is about 58.8%, meanwhile, the chance level is about 0.83%. Using the optimized wights in the main-training stage. We could generate a tuning properties image. It could tell us which orinentation and spatial frequency contribute more to the activity of the voxels. As a given example, for the No.23198 voxel, we visualize the weight distribution of the 8 orintations and 5 spatial frequency (5x8). Figure 7. The weight distribution of the 8 orintation and 5 spatial frequency for the voxel 23198. . Further more, we plot the tuning properties for the orintations separately. Figure 8.The tuning properties for the orintations(L) and spatial frequency(R). . We can observe that, this voxel prefer 45 degres, and relevantly prefer higher special frequency. Consist with the encoding theory of the early visual cortex. ReferencesGilbert, C. D., &amp; Wiesel, T. N. (1985). Intrinsic connectivity and receptive field properties in visual cortex. Vision research, 25(3), 365-374. Chen, N., P. Cai, T. Zhou, B. Thompson, and F. Fang. 2016. ‘Perceptual learning modifies the functional specializations of visual cortical areas’, Proc Natl Acad Sci U S A. Hubel, D. H., and T. N. Wiesel. 1968. ‘Receptive fields and functional architecture of monkey striate cortex’, Journal of Physiology, 195: 215-43. Huth, A. G., W. A. de Heer, T. L. Griffiths, F. E. Theunissen, and J. L. Gallant. 2016. ‘Natural speech reveals the semantic maps that tile human cerebral cortex’, Nature, 532: 453-8. Kandel, E., and J. Schwartz. 2013. Principles of Neural Science, Fifth Edition (McGraw-Hill Education). Kay, K. N., T. Naselaris, R. J. Prenger, and J. L. Gallant. 2008. ‘Identifying natural images from human brain activity’, Nature, 452: 352-5. Miyawaki, Y., H. Uchida, O. Yamashita, M. A. Sato, Y. Morito, H. C. Tanabe, N. Sadato, and Y. Kamitani. 2008. ‘Visual image reconstruction from human brain activity using a combination of multiscale local image decoders’, Neuron, 60: 915-29. Naselaris, T., K. N. Kay, S. Nishimoto, and J. L. Gallant. 2011. ‘Encoding and decoding in fMRI’, NeuroImage, 56: 400-10. Norman, K. A., S. M. Polyn, G. J. Detre, and J. V. Haxby. 2006. ‘Beyond mind-reading: multi-voxel pattern analysis of fMRI data’, Trends Cogn Sci, 10: 424-30. Sprague, T. C., &amp; Serences, J. T. (2013). Attention modulates spatial priority maps in the human occipital, parietal and frontal cortices. Nat Neurosci, 16(12), 1879-1887. doi:10.1038/nn.3574","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"fMRI","slug":"fMRI","permalink":"http://www.jingjie.site/tags/fMRI/"},{"name":"XJTU","slug":"XJTU","permalink":"http://www.jingjie.site/tags/XJTU/"},{"name":"encoding model","slug":"encoding-model","permalink":"http://www.jingjie.site/tags/encoding-model/"},{"name":"MATLAB","slug":"MATLAB","permalink":"http://www.jingjie.site/tags/MATLAB/"},{"name":"Repetation","slug":"Repetation","permalink":"http://www.jingjie.site/tags/Repetation/"}]},{"title":"Visual Image Reconstruction using fMRI","slug":"visual_image_reconstruction","date":"2016-03-09T18:19:55.000Z","updated":"2017-09-22T16:37:54.000Z","comments":true,"path":"2016/03/10/visual_image_reconstruction/","link":"","permalink":"http://www.jingjie.site/2016/03/10/visual_image_reconstruction/","excerpt":"Mind-reading is really amazing and exciting. Using modern fMRI(functional magnetic resonance imaging) technique. We can now decoding some infomation from participant’s brain activities. \nBased on that, I repeated some previous research in Badong Chen’s lab, such as decode fMRI signal from primary visual cortex (V1) and reconstruct pattern image from fMRI signal (Miyawaki et al., 2008). Meanwhile, I improved the accuracy of the reconstruction by about 4% (from about 80% to about 84%), using the improved MVPA method with SVM classifier (Norman et al., 2006).","text":"Mind-reading is really amazing and exciting. Using modern fMRI(functional magnetic resonance imaging) technique. We can now decoding some infomation from participant’s brain activities. Based on that, I repeated some previous research in Badong Chen’s lab, such as decode fMRI signal from primary visual cortex (V1) and reconstruct pattern image from fMRI signal (Miyawaki et al., 2008). Meanwhile, I improved the accuracy of the reconstruction by about 4% (from about 80% to about 84%), using the improved MVPA method with SVM classifier (Norman et al., 2006). IntroductionMind-reading is really amazing and exciting. Using modern fMRI(functional magnetic resonance imaging) technique. We can now decoding some infomation from participant’s brain activities. Based on that, I repeated some previous research in Badong Chen’s lab, such as decode fMRI signal from primary visual cortex (V1) and reconstruct pattern image from fMRI signal (Miyawaki et al., 2008). Meanwhile, I improved the accuracy of the reconstruction by about 4% (from about 80% to about 84%), using the improved MVPA method with SVM classifier (Norman et al., 2006). This article is only a berif introduction of my work. You can contact me for the reconstruction result video demo, for the source code and for more detail. ResultsSubjects view 12x12 binary(Black or White) pixels images while recoding their brain activities using fMRI. 352 of which are in random. 80s are in regular (The pattern of them are like numbers, etc.), see figure below. Figure 1. Left binary image is in random, right is in regular Then we use GLM procedures to modeling brain activity for every stimuli. Firstly, I use MVPA(Multi-Voxels pattern analyze) to build up a model for every pixel (1x1 scale). We then everaged the vaule of 2 neighbouring pixels vertically (2x1 scale) and horizentally (1x2 scale), and 4 neighbouring pixels (2x2 scale). Figure showed below.(Miyawaki et al., 2008) Figure 2. Multi-scale local image bases for buliding MVPA model In MVPA, I firstly choosed 3037 voxels from V1, then caculated Pearson’s r for each voxels. Then sort them using r vaule. We choose the 50 voxels from it(top 30 and last 20). Then we trainning a SVM classifier to build up the MVPA model using 352 random images as a trainning set. The code example showed below. 1function [ SVMStruct,corvox ] = singlevoxtrai(trainingsetnum,posi,beta,stim) %This model train a SVM model to a given posi of the stim % trainingsetnum=1:176; % posi=[6,6]; %% section a,trainnning one single voxal trainingset=beta(:,trainingsetnum); [~,selectvox,~] = voxcor(posi(1,1),posi(1,2),stim(:,:,... trainingsetnum),trainingset);%select the corresponding voxels of the stim Training=beta(selectvox,trainingsetnum)'; Group=reshape(stim(posi(1,1),posi(1,2),:),size(stim,3),1); Group=Group(trainingsetnum,:); SVMStruct = svmtrain(Training,Group,'kernel_function','polynomial'); corvox=selectvox; end Then we use the remaining 80 examples to test our model, using the MVPA models we trainned before, to compute the pixels’ vaule given brain activities. Repeat these procedures to every pixels in 4 scale. After combining 4 scale using liner regression for each pixels. Finally, we got a reconstructed image using subject’s brain activities. We compute deviation using reconstruced image and the actually image (square-root error). The example show below. Figure 3. The demo video of the reconstructed image This article is only a berif introduction of my work. You can contact me for the reconstruction result video demo, for the source code and for more detail. References Miyawaki, Yoichi, et al. “Visual image reconstruction from human brain activity using a combination of multiscale local image decoders..” Neuron60.5(2008):915-29. Norman, K. A et al.,(2006). Beyond mind-reading: multi-voxel pattern analysis of fMRI data. Trends Cogn Sci, 10(9), 424-430. doi:10.1016/j.tics.2006.07.005","raw":null,"content":null,"categories":[{"name":"Research Experience","slug":"Research-Experience","permalink":"http://www.jingjie.site/categories/Research-Experience/"}],"tags":[{"name":"Scholar","slug":"Scholar","permalink":"http://www.jingjie.site/tags/Scholar/"},{"name":"fMRI","slug":"fMRI","permalink":"http://www.jingjie.site/tags/fMRI/"},{"name":"XJTU","slug":"XJTU","permalink":"http://www.jingjie.site/tags/XJTU/"},{"name":"MATLAB","slug":"MATLAB","permalink":"http://www.jingjie.site/tags/MATLAB/"},{"name":"Repetation","slug":"Repetation","permalink":"http://www.jingjie.site/tags/Repetation/"},{"name":"MVPA","slug":"MVPA","permalink":"http://www.jingjie.site/tags/MVPA/"}]}]}